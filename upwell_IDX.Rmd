---
title: "upwell_IDX"
author: "Amieroh Abrahams"
date: "08 August 2019"
output: html_document
---

# Upwelling

Upwelling is primarily caused by alongshore, equator ward winds. These winds are caused by cross-shore atmospheric pressure gradients, and these gradients occur predominantly during heating periods. Upwelling is defined as the process whereby cold, nutrient rich, high concentrated CO2, low pH, and low oxygenated waters are pushed to the surface as a result of alongshore winds interacting with the earth’s rotation

# Upwelling indeces
  # Determining upwelling index from wind data (SAWS)
  # Index Equation from Fielding & Davis 1989 paper

$$ UpwellingIndex = μ{(Cosθ − 160)}$$

In this equation μ represents the wind speed (m/s) and θ represents the wind direction which is measured in degrees. The 160 degrees is used as this refers to the angle of the coastline. This equation is largely dependant on wind speed and direction data in order to determining the intensity of the upwelling event. Wind data were obtained daily from the South African Weather Service (SAWS). This wind data were then matched to the date at which temperatures were collected. With these data the upwelling index was determined.

# libraries

```{r}
# Installing and loading libraries

library(circular)
## devtools::install_github("robwschlegel/coastR")
library(gridExtra)
library(geosphere)
library(tidyverse)
library(heatwaveR)
library(coastR)
```

# Steps
  - Use the circular function
  - Determine daily wind data obtained from 3hr intervals

```{r, eval=FALSE}
wind_1 <- read.delim("Data/Wind_data/wind_data.txt(SAWS)/wind1/wind1.txt", na.strings = "",
                     col.names = c("station_number", "station_name", "date", "hour", "sub", "speed", "dir"))

wind_2 <- read.delim("Data/Wind_data/wind_data.txt(SAWS)/wind2/wind2.txt", na.strings = "",
                     col.names = c("station_number", "station_name", "date", "hour", "sub" ,"speed", "dir"))

wind_3 <- read.delim("Data/Wind_data/wind_data.txt(SAWS)/wind3/wind3.txt", na.strings = "",
                     col.names = c("station_number", "station_name", "date", "hour", "sub" ,"speed", "dir"))

# Selecting the important columns for each of the datasets
## Renaming the sites within the wind datasets to match the name of the sites at which seawater temperature was collected
## The wind data was obtained from the SAWS and the wind stations used were the closes stations to which temperature was collected
wind_fix <- function(df){
wind <- df %>%
  mutate(date = as.Date(as.character(date)),
         hour = as.numeric(as.character(hour)),
         dir = as.numeric(as.character(dir)),
         speed = as.numeric(as.character(speed)),
         temp_sites = case_when(station_name == "CAPE TOWN TABLE BAY" ~ "Sea Point",
                                station_name == "CAPE TOWN - ROYAL YACHT CLUB" ~ "Sea Point",
                                station_name  == "PORT NOLLOTH" ~"Port Nolloth",
                                station_name  == "CAPE TOWN SLANGKOP" ~ "Hout Bay",
                                station_name  == "LAMBERTSBAAI NORTIER" ~ "Lamberts Bay",
                                station_name  == "LANGEBAANWEG AWS" ~ "Saldanha Bay")) %>% 
  dplyr::select(temp_sites, date, hour, dir, speed) %>% 
  drop_na()
}

wind_fix_1 <- wind_fix(df = wind_1)
wind_fix_2 <- wind_fix(df = wind_2)
wind_fix_3 <- wind_fix(df = wind_3)

# Combine and save
wind_data <- rbind(wind_fix_3, wind_fix_2, wind_fix_1)
#save(wind_data, file = "Data/wind_data.RData")
# load("Data/wind_data.RData")
selected_sites <- c("Port Nolloth", "Lamberts Bay", "Sea Point", "Saldanha Bay")

# RWS: Please figure out why some wind direction values are returned as NA
# RWS: Also, it's not enough to just calculate mean speed. It needs to be taken into account with the directions.
# RWS: Please look through these resources and make corrections accordingly:
# https://cran.r-project.org/web/packages/rWind/rWind.pdf
# https://www.kaggle.com/srlightfoote/example-wind-analysis-in-r



wind_daily <- wind_data %>% 
  filter(temp_sites %in% selected_sites) %>%  # Matching the sites to wind temp sites
  dplyr::group_by(temp_sites, date) %>%
  dplyr::summarise(dir_circ = round(mean.circular(circular(dir, units = "degrees", 
                                                           template = 'geographics')),2),
                                    spw_circ = mean.circular(circular(speed, units = "degrees"))) # Direction using the circular function

save(wind_daily, file = "Data/wind_daily.RData") 
```

# Load wind

```{r}
load("Data/wind_daily.RData") 
wind_daily <- wind_daily %>%
  dplyr::rename(sites = temp_sites) %>% 
  drop_na()
load("Data/site_list_sub.Rdata")
load("Data/SACTN_US.RData")
```

# Determining the angle perpendicular to the coastline and plotting it

```{r}
# Coast R- function that calculates the angle of the site perpendicular to the coastline
# Transect function in coastR package finds the angle away or along the coastline
south_africa_away_wide <- coastR::transects(site_list_sub, spread = 30) %>% 
  mutate(heading = ifelse(heading < 0, heading+360, heading))

# Plotting the map
world_map <- ggplot() + 
  borders(fill = "grey40", colour = "black")

# Plotting function
# plot_sites <- function(site_list, buffer, dist){
  
  # Find the point 200 km from the site manually to pass to ggplot
#   heading2 <- data.frame(geosphere::destPoint(p = select(site_list, lon, lat),  
#                                               b = site_list$heading, d = dist))
#   
#   # Add the new coordinates tot he site list
#   site_list <- site_list %>% 
#     mutate(lon_dest = heading2$lon,
#            lat_dest = heading2$lat)
#   
#   # Visualise
#   world_map +
#     geom_segment(data = site_list, colour = "red4", 
#                  aes(x = lon, y = lat, xend = lon_dest, yend = lat_dest)) +
#     geom_point(data = site_list, size = 3, colour = "black", aes(x = lon, y = lat)) +
#     geom_point(data = site_list, size = 3, colour = "red", aes(x = lon_dest, y = lat_dest)) +
#     coord_cartesian(xlim = c(min(site_list$lon - buffer), 
#                              max(site_list$lon + buffer)),
#                     ylim = c(min(site_list$lat - buffer), 
#                              max(site_list$lat + buffer))) +
#     labs(x = "", y = "", colour = "Site\norder")
# }
# south_africa_away <- plot_sites(south_africa_away_wide, 1, 100000)
# south_africa_away
```

# Upwelling indeces using the above formula

```{r}
UI_angle <- wind_daily %>%  # Making reference to the wind daily data created above
  dplyr::rename(site = sites) %>%  # Renaming sites to site
  left_join(south_africa_away_wide[,c(2,21)], by = "site") %>%  # Joining wind data to South Africa wide data column 2 and 21. by site 
  drop_na() %>% # removing the na values
  dplyr::rename(coast_angle = heading) %>% # Renaming the column heading to coast_angle
  mutate(ui.saws = mean_speed * (cos(dir_circ - coast_angle))) %>% # applying the ui formula
  dplyr::rename(t = date) %>% 
  drop_na()#renaming date to t



# save(UI_angle, file = "Data/UI_angle.RData")
# index <- wind_UI %>%
#   group_by(site) %>%
#   select("date", "ui.saws") %>%
#   mutate(saws.condition = ifelse(ui.saws < 12.5, "upwelling"))
# wind_UI <- wind_daily %>% 
#   mutate(ui.saws = mean_speed * (cos(dir_circ - 160))) %>% # 160 is angle perpendicular to the west coast of SA (See paper Fielding and Davis pg 182)
#   drop_na
# Results obtained from UI_angle (Using the perpendicular angle for each site) and the results of wind_UI at -160 (angle of the west coast) appears to be the same
```

# Exceedence function heatwaveR 
This is done to determine the consecutive number of days at or above what the UI value is meant to be   # Detect consecutive days in exceedance of a given threshold.

```{r}
# Loading the insitu temperature data along the wc
load("Data/SACTN_US.RData") # temperature data for all the sites with a 30year time series
# exceedance <-
#   function(data,
#            x = t,
#            y = temp,
#            threshold,
#            below = FALSE,
#            minDuration = 5,
#            joinAcrossGaps = TRUE,
#            maxGap = 2,
#            maxPadLength = 3)
# Upwelling temperature threshold 12.4 / 30th percentile
SACTN_upwell <- UI_angle %>% 
  dplyr::rename(temp = ui.saws) %>%
  group_by(site) %>%
  # mutate(min_t = min(t), 
  #        max_t = max(t)) %>% 
  nest() %>% # apply the following functions to all of the variables in te dataset
  mutate(clim = purrr::map(data, ts2clm, climatologyPeriod = c("1992-01-01", "2016-12-31")), # creating a column of climaatologies. Column will be named clim
         # NB: A threshold of 3 appeared to be far to strict
         # purr::map - apllies a function to each element of a vector
         exceed = purrr::map(clim, exceedance, minDuration = 1, threshold = 1)) %>%  #Upwelling cannot be descrbed as an event. Upwelling can last for a few hours. Given that we have daily data, upwelling events minimum duration here will be 1day
  # Detect consecutive days in exceedance of a given threshold.
  # mutate() %>% 
  select(-data, -clim) %>% 
  unnest() %>%
  filter(row_number() %% 2 == 1) %>%
  unnest() %>% # creates a column for each variables
  dplyr::rename(ui.saws = temp) %>% # rename upwelling index vale to temp so that it could work with the function
  select(site, t, ui.saws, exceedance) # selecting only these variables
# Calculate quantiles of upwelling index

# Static numbers are often rejected and so we decided to find a percentile value as these are often more likely to be approved

SACTN_upwell_quantiles <- SACTN_upwell %>% 
  filter(ui.saws >= 0) %>% # Upwelling occurs for all values above 0. Values below this is regarded as downwelling
  group_by(site) %>% 
  summarize(quant_10 = quantile(ui.saws, probs = 0.10, na.rm = TRUE),
            quant_25 = quantile(ui.saws, probs = 0.25, na.rm = TRUE),
            quant_50 = quantile(ui.saws, probs = 0.50, na.rm = TRUE),
            quant_75 = quantile(ui.saws, probs = 0.75, na.rm = TRUE),
            quant_90 = quantile(ui.saws, probs = 0.90, na.rm = TRUE)) %>% 
  mutate_if(is.numeric, round, digits = 2)

# SACTN_upwell_transform <- as.data.frame(read.zoo(transform( SACTN_upwell, Date = as.POSIXct(t) ), FUN = identity ))
# There are a few ideas on how to go about doing this
# The first is to calculatea rolling climatology and to check the upwelling phenology agianst that
# in order to determine changes in upwelling values, but this won't give us the metrics we want
# Rather what we can do is set a static bottom threshold below which we are interested in looking for upwelling
# We then use the upwelling index values created above as a second filter to determine the metrics of the upwelling
# Unfortunately the way that the heatwaveR functions work well does with purrr. 
# I've figured this out once before but can't remember where now.
# Rather than go through the process I have rather just made a convenience function below that
# does what I want and can simply be given to purrr::map() without any faffing about.


# Detect event: 
detect_event_custom <- function(df){
  res <- detect_event(df, threshClim2 = df$exceedance, minDuration = 3, coldSpells = T)
  return(res)
}
# Calculate the upwelling event metrics
SACTN_upwell_base <- SACTN_US %>% 
  dplyr::rename(t = date) %>% 
  group_by(site) %>% 
  nest() %>% 
  # The climatology base period used here is up for debate...
  # The choice of the 30th percentile threshold also needs to be justified and sensitivty tested
  mutate(clim = purrr::map(data, ts2clm, pctile = 25, climatologyPeriod = c("1995-01-01", "2004-12-31"))) %>%
  select(-data) %>% 
  unnest() %>%
  left_join(SACTN_upwell, by = c("site", "t")) %>%
  filter(!is.na(exceedance)) %>%
  group_by(site) %>% 
  # mutate(thresh = mean(seas, na.rm = T)-sd(seas, na.rm = T)) %>% # Manually set threshold to the mean
  # mutate(thresh = 10) %>% # Manually set threshold to a static value. Doesn't work across all sites
  # mutate(thresh = quantile(temp, 0.3, na.rm = T)) %>% # Manually set threshold to a single quantile
  nest() %>% 
  mutate(exceed = purrr::map(data, detect_event_custom)) %>% 
  select(-data) #%>% 
  # unnest() %>% 
  # filter(row_number() %% 2 == 0) %>% # Select event summary metrics
  # filter(row_number() %% 2 == 1) %>% # Select daily values
  # unnest()
# Unpack the event metric reults
SACTN_upwell_events <- SACTN_upwell_base %>% 
  unnest() %>%
  filter(row_number() %% 2 == 0) %>%
  unnest()
# save(SACTN_upwell_events, file = "Data/SACTN_upwell_events.RData")
# Unpack the daily climatology results
SACTN_upwell_clims <- SACTN_upwell_base %>% 
  unnest() %>%
  filter(row_number() %% 2 == 1) %>% 
  unnest()
# save(SACTN_upwell_clims, file = "Data/SACTN_upwell_clims.RData")
# The above chunk of code appears to work as expected.
# What needs to be done now is that the thresholds for duration and UI strength need to be justified/decided uopn. 
    # Min duration for an upwelling event - 1day and threshold -1
# What also needs to be decided is if we are interested in any upwelling results throughout the year,
# or only during the upwelling season, whenever that may be for each site.
# I think we have demonstrated the technical capability needed to answer the question of whether or not upwelling
# is changing over time.
# Now we really need to focus on which of these parameters need to best be tweaked to answer that question.
```

# MCS and upwelling indeces plot

```{r}
# match_func <- function(df){
#   match <- SACTN_MCS_clims  %>% 
#   left_join(df, by = c("site", "t")) %>% 
#   na.trim()
#   return(match)
# }
# 
# index <- index %>% 
#   dplyr::rename(site = sites) %>% 
#   dplyr::rename(t = date)
# 
# match <- match_func(df = index)
# 
# upwell_MCS <- ggplot(data = match, aes(x = t, y = ui.saws)) +
#   geom_line() +
#   geom_point(data = filter(match, event == TRUE), colour = "navy") +
#   geom_rug(data = filter(match, saws.condition == "upwelling"), sides = "b") +
#   scale_x_date(expand = c(0, 0)) +
#   facet_wrap(~site, ncol = 1) +
#   theme_grey() +
#   labs(y = "Temperature (°C)", x = NULL)
# upwell_MCS
# Plot some of the Upwelling/MCS results
SP_upwelling <- SACTN_upwell_clims %>% 
  filter(site == "Sea Point", lubridate::year(t) %in% 2016:2018)
plot1 <- ggplot(SP_upwelling, aes(x = t, y = temp)) +
  geom_flame(aes(y = thresh, y2 = temp), fill = "navy", n = 3) +
  geom_point(data = filter(SP_upwelling, !is.na(event_no))) +
  geom_line(aes(y = thresh)) +
  geom_line(alpha = 0.7) +
  geom_rug(data = filter(SP_upwelling, event_no > 0), sides = "b")
plot1
  
# The dots on the plot help to show the length of each wind driven upwelling event detected.
# This supports the use of this methodology.
# Up next is fitting linear models to the upwelling metric results to see what trends shake out.
# Linear Models
lm_coeff <- function(df){
  res <- lm(formula = val ~ date_peak, data = df)
  res_coeff <- round(as.numeric(res$coefficient[2]), 4)
}
# Changes in upwelling metrics
SACTN_upwell_lm <- SACTN_upwell_events %>% 
  select(-c(index_start:index_end)) %>% 
  gather(key = "var", value = "val", -c(site:date_end)) %>% 
  group_by(site, var) %>% 
  nest() %>% 
  mutate(slope = purrr::map(data, lm_coeff)) %>% 
  select(-data) %>% 
  unnest() %>% 
  # convert from daily to decadal values
  mutate(slope = slope * 365.25*10)
```












