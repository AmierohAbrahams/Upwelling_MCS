---
title: "SST_patterns"
author: "Amieroh Abrahams"
date: "19 August 2019"
output: html_document
---
# This script is for all the various datasets

# Are the same upwelling signals present at different distances from the coastline and throughout the different datasets

```{r}
knitr::opts_chunk$set(
  comment = "R>",
  warning = FALSE,
  message = FALSE 
)
#update.packages() 
library(tidyverse)
library(lubridate)
library(ggpubr)
library(zoo)
library(FNN)
library(scales)
library(gridExtra)
library(circular)
library(fossil)
library(mapproj)
library(broom)
# library(ncdf4) # This was used to process NetCDF files in an earlier version
library(stringr)
library(doMC); doMC::registerDoMC(cores = 4)
library(fasttime)
library(xtable)
library(ncdf4) # library for processing netCDFs
library(data.table)
# library(plyr) # RWS: Never load the plyr package as it interferes with the tidyverse
library(heatwaveR)
library(grid)
library(ggthemes)
```

# Loading in all the data created using the code bellow

```{r}
load("Data/site_list_sub.Rdata")
load("Data/SACTN_US.RData")
load("Data/site_pixels.RData") # 5 decimal places
load("Data/OISST.RData") # 2 decimal places
OISST <- BC_avhrr_only_v2_Document_Document 
rm(BC_avhrr_only_v2_Document_Document ); gc()
load("Data/CMC.RData") # 1decimal places
```

# PLotting theme

```{r}
theme_Publication <- function(base_size=14, base_family="helvetica") {
      library(grid)
      library(ggthemes)
      (theme_foundation(base_size=base_size, base_family=base_family)
       + theme(plot.title = element_text(face = "bold",
                                         size = rel(1.2), hjust = 0.5),
               text = element_text(),
               panel.background = element_rect(colour = NA),
               plot.background = element_rect(colour = NA),
               panel.border = element_rect(colour = NA),
               axis.title = element_text(face = "bold",size = rel(1)),
               axis.title.y = element_text(angle=90,vjust =2),
               axis.title.x = element_text(vjust = -0.2),
               axis.text = element_text(), 
               axis.line = element_line(colour="black"),
               axis.ticks = element_line(),
               panel.grid.major = element_line(colour="#f0f0f0"),
               panel.grid.minor = element_blank(),
               legend.key = element_rect(colour = NA),
               legend.position = "bottom",
               legend.direction = "horizontal",
               legend.key.size= unit(0.2, "cm"),
               legend.margin = unit(0, "cm"),
               #legend.title = element_text(face="italic"),
               plot.margin=unit(c(10,5,5,5),"mm"),
               strip.background=element_rect(colour="#f0f0f0",fill="#f0f0f0"),
               strip.text = element_text(face="bold")
          ))
      
}

scale_fill_Publication <- function(...){
      library(scales)
      discrete_scale("fill","Publication",manual_pal(values = c("#386cb0","#fdb462","#7fc97f","#ef3b2c","#662506","#a6cee3","#fb9a99","#984ea3","#ffff33")), ...)

}

scale_colour_Publication <- function(...){
      library(scales)
      discrete_scale("colour","Publication",manual_pal(values = c("#386cb0","#fdb462","#7fc97f","#ef3b2c","#662506","#a6cee3","#fb9a99","#984ea3","#ffff33")), ...)

}
```


```{r}
# SACTN_US <- SACTN_US %>% 
#   dplyr::rename(in_situ_temp = temp)
# 
# # Visualising the data
# temp_plot <- function(df){
#   plot <- ggplot(data = df, aes(x = date, y = in_situ_temp, colour = site)) +
#     geom_line(aes(group = site)) +
#     labs(x = "", y = "Temperature (°C)") +
#     theme(axis.text.x = element_text(angle = 45)) +
#     theme(legend.position = "top")
# }
# 
# SACTN_plot <- temp_plot(df = SACTN_US)
# SACTN_plot


# 25th quantile
```

Different distances from the coastline

```{r}
# load("Data/site_list_sub.Rdata")
# # xtable(site_list_sub, auto = TRUE)
# west <- site_list_sub
# west$coast <- "west" # Chnages wc to west
# 
# load("Data/africa_coast.RData")
# 
# ## Downloading the bathy data from NOAA
# # Download mid-res bathymetry data
# # sa_lat <- c(-38, -24.5); sa_lon <- c(11.5, 35.5)
# # sa_bathy <- as.xyz(getNOAA.bathy(lon1 = sa_lon[1], lon2 = sa_lon[2], lat1 = sa_lat[1], lat2 = sa_lat[2], resolution = 4))
# # colnames(sa_bathy) <- c("lon", "lat", "depth")
# # sa_bathy <- sa_bathy[sa_bathy$depth <= 0,]
# # save(sa_bathy, file = "Data_P1/bathy/sa_bathy.RData")
# 
# # Loading in the newly downloaded bathymetry data               
# load("Data/bathy/sa_bathy.RData")

# # This function takes one site (e.g. one set of lon/lats) and calculates a shore normal transect
# shore.normal.transect <- function(site, width = 2){
#   # Find the site on the coastline and it's nearest neighbour points
#   coords <- data.frame(lon = site$lon, lat = site$lat)
#   coords2 <- knnx.index(africa_coast[,1:2], as.matrix(coords), k = 1)
#   coords3 <- data.frame(site = site$site, africa_coast[c(coords2-width, coords2+width),]) 
#   coords3 <- coords3[2:1,1:3]
#   # Define the shore normal transect bearing
#   heading <- earth.bear(coords3[1,2], coords3[1,3], coords3[2,2], coords3[2,3]) + 90
#   if(heading >= 360){
#     heading <- heading-360
#   } else {
#     heading <- heading
#   }
#   heading2 <- data.frame(site = site$site, lon = site$lon, lat = site$lat, heading)
#   return(heading2)
# }
# 
# # Creating the transects
# site_transects <- data.frame()
# for(i in 1:length(west$site)){
#  site <- west[i,]
#  site_transect <- shore.normal.transect(site, 2)
#  site_transects <- rbind(site_transects, site_transect)
# }
# 
# # Manually correcting Sea Point and Kommetjie
# site_transects$heading[4:5] <- 290 
# # save(site_transects, file = "Data/site_transects.RData")
# load("Data/site_transects.RData")
# 
# # This function takes one site (e.g. one set of lon/lats) and calculates a shore norm./subal transect
# # It then extracts a lat/ lon point every X kilometres until reaching a specified isobath
# 
# transect.pixel <- function(site, distances){
#   # Extract coordinates
#   coords <- data.frame(lon = site$lon, lat = site$lat)
#   # Find lon/ lats every X metres 
#   pixels <- data.frame()
#   # deep <- 999
#   # distance_multiplier <- 1
#   # while(deep > isobath){
#   for(i in 1:length(distances)){
#     coords2 <- as.data.frame(destPoint(p = coords, b = site$heading, d = distances[i]))
#     sitesIdx <- knnx.index(sa_bathy[,1:2], as.matrix(coords2), k = 1)
#     bathy2 <- sa_bathy[sitesIdx,]
#     bathy2 <- bathy2[complete.cases(bathy2$depth),]
#     bathy3 <- data.frame(site = site$site, lon = bathy2$lon, lat = bathy2$lat, 
#                          heading = site$heading, 
#                          distance = distances[i])
#     pixels <- rbind(pixels, bathy3)
#     coords <- coords2
#   }
#   if(nrow(pixels) < 1){
#     pixels <- data.frame(site, depth = NA)
#   }else{
#     pixels <- pixels
#   }+

#   return(pixels)
# }
# 
# # Pixel points
# site_pixels <- data.frame()
# for(i in 1:length(west$site)){
#   site <- site_transects[i,]
#   site_pixel <- transect.pixel(site, c(10000, 20000, 30000, 40000, 50000)) # RWS: fixed error
#   site_pixels <- rbind(site_pixels, site_pixel)
# }
# 
# # Bounding box
#   # Only one is made in order to know how large the the geom_point() squares should be made to match
# bbox <- data.frame(xmin = destPoint(p = site_pixels[1,2:3], b = 270, d = 12500)[1],
#                    xmax = destPoint(p = site_pixels[1,2:3], b = 90, d = 12500)[1],
#                    ymin = destPoint(p = site_pixels[1,2:3], b = 180, d = 12500)[2],
#                    ymax = destPoint(p = site_pixels[1,2:3], b = 0, d = 12500)[2])
# 
# # Determining the temperature at the various distances from the coast
# 
# # save(site_pixels, file = "Data/site_pixels.RData")
# load("Data/site_pixels.RData")


```

# Extrcting the MUR data

```{r}
# library(stringr)
# library(tidyverse)
# library(reshape2)
# library(ncdf4) # library for processing netCDFs
# library(plyr)
# library(lubridate)
# library(data.table)
# library(doMC); doMC::registerDoMC(cores = 7)
# 
# ncDir <- "/home/amieroh/Documents/Data/Datasets/MUR/daily"
# csvDir <- "/media/amieroh/Seagate Expansion Drive/Extracted G1SST/MUR_extracted"
# 
# #          1         2         3         4
# # 12345678901234567890123456789012345678901
# # 20020601-JPL-L4UHfnd-GLOB-v01-fv04-MUR.nc
# 
# read_nc <- function(ncDir = ncDir, csvDir = csvDir)
#   ncList <- list.files(path = paste0(ncDir), pattern = "*.nc", full.names = TRUE, include.dirs = TRUE)
#   ncFirst <- head(list.files(path = paste0(ncDir, "/"), pattern = "*.nc", full.names = FALSE), 1)
#   ncLast <- tail(list.files(path = paste0(ncDir, "/"), pattern = "*.nc", full.names = FALSE), 1)
#   strtDate <- str_sub(ncFirst, start = 1, end = 8)
#   endDate <- str_sub(ncLast, start = 1, end = 8)
# 
# # ncFile <- '/home/amieroh/Documents/Data/Datasets/MUR/daily/20020606-JPL-L4UHfnd-GLOB-v01-fv04-MUR.nc'
# 
#   ncFun <- function(ncFile = ncFile, csvDir = csvDir) {
#     nc <- nc_open(ncFile)
#     pathLen <- nchar(paste0(ncDir, "/")) + 1
# fNameStem <-
#   substr(basename(ncFile), 10, 38)
#     fDate <- substr(basename(ncFile), 1, 8)
#     sst <- ncvar_get(nc, varid = "analysed_sst") %>%
#       round(4)
#     dimnames(sst) <- list(lon = nc$dim$lon$vals,
#                           lat = nc$dim$lat$vals)
#     nc_close(nc)
#     sst <- as_tibble(melt(sst, value.name = "temp"))
#     sst$t <- ymd(fDate)
#     na.omit(sst)
#     fwrite(sst,
#            file = paste0(csvDir, "/", fNameStem, "-", strtDate, "-", endDate, ".csv"),
#            append = TRUE, col.names = FALSE)
#     rm(sst)
#   }
# 
# llply(ncList, ncFun, csvDir = csvDir, .parallel = TRUE)

# MUR <- read_csv("/home/amieroh/Documents/Data/Datasets/MUR/Extracted_MUR/BC-JPL-L4UHfnd-GLOB-v01-fv04-MUR-20020601-20140727.csv")
# names(MUR)<-c("lon","lat", "temp", "date")
# MUR <- MUR %>% 
#   mutate(temp = temp - 273.15)
# 
# JPL_L4UHfnd_GLOB_v01_fv04_MUR_20020601_20140727 <- read_csv("~/Documents/JPL-L4UHfnd-GLOB-v01-fv04-MUR-20020601-20140727.csv")
# 
# ######################################### SUBSET VIA REGION #################
# 
# # bbox <- data.frame(BC = c(-35, -25, 15, 20), # Benguela Current
# library(stringr)
# library(tidyverse)
# library(reshape2)
# library(ncdf4) # library for processing netCDFs
# library(plyr)
# library(lubridate)
# library(data.table)
# library(doMC); doMC::registerDoMC(cores = 7)
# ncDir <- "/home/amieroh/Documents/Data/Datasets/MUR/daily"
# csvDir <- "/home/amieroh/Documents/Data/Datasets/MUR/Extracted_MUR"
# #          1         2         3         4
# # 12345678901234567890123456789012345678901
# # 20020601-JPL-L4UHfnd-GLOB-v01-fv04-MUR.nc
# 
# # ncFile <- '/home/amieroh/Documents/Data/Datasets/MUR/daily/20020606-JPL-L4UHfnd-GLOB-v01-fv04-MUR.nc'
#   ncFun <- function(ncFile = ncFile, region = region, csvDir = csvDir) {
#     coords <- bbox[, region]
#     nc <- nc_open(ncFile)
#     pathLen <- nchar(paste0(ncDir, "/")) + 1
#     fNameStem <-
#       substr(basename(ncFile), 10, 38)
#     fDate <- substr(basename(ncFile), 1, 8)
#     LatIdx <- which(nc$dim$lat$vals > coords[1] & nc$dim$lat$vals < coords[2])
#     LonIdx <- which(nc$dim$lon$vals > coords[3] & nc$dim$lon$vals < coords[4])
#     sst <- ncvar_get(nc, varid = "analysed_sst") %>%
#       round(4)
#     dimnames(sst) <- list(lon = nc$dim$lon$vals,
#                           lat = nc$dim$lat$vals)
#     nc_close(nc)
#     sst <- as_tibble(melt(sst, value.name = "temp"))
#     sst$t <- ymd(fDate)
#     na.omit(sst)
#     fwrite(sst,
#            file = paste0(csvDir, "/", region, "-", fNameStem, "-", strtDate, "-", endDate, ".csv"),
#            append = TRUE, col.names = FALSE)
#     rm(sst)
#   }
#   
#   
#   ncList <- list.files(path = paste0(ncDir), pattern = "*.nc", full.names = TRUE, include.dirs = TRUE)
#   ncFirst <- head(list.files(path = paste0(ncDir, "/"), pattern = "*.nc", full.names = FALSE), 1)
#   ncLast <- tail(list.files(path = paste0(ncDir, "/"), pattern = "*.nc", full.names = FALSE), 1)
#   strtDate <- str_sub(ncFirst, start = 1, end = 8)
#   endDate <- str_sub(ncLast, start = 1, end = 8)  
#   
# llply(ncList, ncFun, region = "BC", csvDir = csvDir, .parallel = TRUE)
```

# Extracting the CMC data

```{r}
# ncDir <- "/home/amieroh/Documents/Data/Datasets/CMC/CMC_BC"
# csvDir <- "/home/amieroh/Documents/Data/Datasets/CMC/CMC_extracted"
# 
# #          1         2         3         4         5         6
# # 123456789012345678901234567890123456789012345678901234567890
# # 20100609-JPL_OUROCEAN-L4UHfnd-GLOB-v01-fv01_0-G1SST_subset.nc
# read_nc <- function(ncDir = ncDir, csvDir = csvDir) 
#   ncList <- list.files(path = paste0(ncDir), pattern = "*.nc", full.names = TRUE, include.dirs = TRUE)
#   ncFirst <- head(list.files(path = paste0(ncDir, "/"), pattern = "*.nc", full.names = FALSE), 1)
#   ncLast <- tail(list.files(path = paste0(ncDir, "/"), pattern = "*.nc", full.names = FALSE), 1)
#   strtDate <- str_sub(ncFirst, start = 1, end = 8)
#   endDate <- str_sub(ncLast, start = 1, end = 8)
# 
# # ncFile <- '/home/amieroh/Documents/Data/Datasets/CMC/CMC_BC/20100609-JPL_OUROCEAN-L4UHfnd-GLOB-v01-fv01_0-G1SST_subset.nc'
# 
#   ncFun <- function(ncFile = ncFile, csvDir = csvDir) {
#     nc <- nc_open(ncFile)
#     pathLen <- nchar(paste0(ncDir, "/")) + 1
#     fNameStem <-
#       substr(basename(ncFile), 10, 58)
#     fDate <- substr(basename(ncFile), 1, 8)
#     sst <- ncvar_get(nc, varid = "analysed_sst") %>%
#       round(4)
#     dimnames(sst) <- list(lon = nc$dim$lon$vals,
#                           lat = nc$dim$lat$vals)
#     nc_close(nc)
#     sst <- as_tibble(melt(sst, value.name = "temp"))
#     sst$t <- ymd(fDate)
#     na.omit(sst)
#     fwrite(sst,
#            file = paste0(csvDir, "/", fNameStem, "-", strtDate, "-", endDate, ".csv"),
#            append = TRUE, col.names = FALSE)
#     rm(sst)
#   }
# 
# llply(ncList, ncFun, csvDir = csvDir, .parallel = TRUE)
# 
# 
# CMC <- read_csv("/home/amieroh/Documents/Data/Datasets/CMC/CMC_extracted/Benguela_current/20000-CMC-L4_GHRSST-SSTfnd-CMC0.2deg-GLOB-v02.0-f-19910901-20170317.csv")
# names(CMC)<-c("lon","lat", "temp", "date")
# CMC <- CMC %>% 
#   mutate(temp = temp - 273.15)
# 
# # save(CMC, file = "Data/CMC.RData")
```

# Extracting the OISST data

```{r}
# bbox <- data.frame(BC = c(-35, -25, 15, 20), # Benguela Current
#                    CC = c(25, 35, 340, 355), # Canary Current
#                    CalC = c(35, 45, 225, 240), # California Current
#                    HC = c(-17.5, -7.5, 275, 290), # Humboldt Current
#                    row.names = c("latmin", "latmax", "lonmin", "lonmax"))
# 
# OISST.dir <- "/home/amieroh/Documents/Data/Datasets/OISSTv2/daily/netCDF/avhrr-only"
# OISST.csv.dir <- "/home/amieroh/Documents/Data/Datasets/OISST_subset"
# 
# #          1         2
# # 1234567890123456789012345
# # avhrr-only-v2.19810901.nc
# 
# # function to extract the dims and data from OISST netCDFs
# read_nc <- function(ncFile, region = region, csvDir = csvDir) {
#   coords <- bbox[, region]
#   nc <- nc_open(ncFile)
#   pathLen <- nchar(OISST.dir) + 1 # to account for the "/" that needs to be inserted
#   fNameStem <-
#     substr(ncFile, pathLen + 1, pathLen + 13)
#   fDate <- substr(ncFile, pathLen + 15, pathLen + 22)
#   LatIdx <- which(nc$dim$lat$vals > coords[1] & nc$dim$lat$vals < coords[2])
#   LonIdx <- which(nc$dim$lon$vals > coords[3] & nc$dim$lon$vals < coords[4])
#   sst <- ncvar_get(nc,
#                    varid = "sst",
#                    start = c(LonIdx[1], LatIdx[1], 1, 1),
#                    count = c(length(LonIdx), length(LatIdx), 1, 1)) %>%
#     round(4)
#   dimnames(sst) <- list(lon = nc$dim$lon$vals[LonIdx],
#                         lat = nc$dim$lat$vals[LatIdx])
#   nc_close(nc)
#   sst <-
#     as.data.table(melt(sst, value.name = "temp"), row.names = NULL) %>%
#     mutate(t = ymd(fDate)) %>%
#     na.omit()
#   fwrite(sst,
#          file = paste(csvDir, "/", region, "-", fNameStem, ".", strtDate, "-", endDate, ".csv", sep = ""),
#          append = TRUE, col.names = FALSE)
#   rm(sst)
# }
# 
# # the list of files
# ncList <- list.files(path = OISST.dir, pattern = "*.nc", full.names = TRUE, include.dirs = TRUE)
# strtDate <- str_sub(ncList[1], start = 15, end = 22)
# endDate <- str_sub(ncList[length(ncList)], start = 15, end = 22)
# 
# # apply the function
# system.time(llply(ncList, read_nc, region = "BC", csvDir = OISST.csv.dir, .parallel = TRUE))
# # system.time(llply(ncList, read_nc, region = "CC", csvDir = OISST.csv.dir, .parallel = TRUE))
# # system.time(llply(ncList, read_nc, region = "CalC", csvDir = OISST.csv.dir, .parallel = TRUE))
# # system.time(llply(ncList, read_nc, region = "HC", csvDir = OISST.csv.dir, .parallel = TRUE))
# 
# # Loading the data
# BC_avhrr_only_v2_Document_Document <- read_csv("~/Documents/OISST_subset/BC-avhrr-only-v2.Document-Document.csv" )
# names(BC_avhrr_only_v2_Document_Document)<-c("lon","lat", "temp", "date")
# 
# # Saving the data
# save(BC_avhrr_only_v2_Document_Document, file = "Data/OISST.RData")
```

# Extracting G1SST

```{r}
# bbox <- data.frame(BC = c(-35, -25, 15, 20)) # Benguela Current
# library(stringr)
# library(tidyverse)
# library(reshape2)
# library(ncdf4) # library for processing netCDFs
# library(plyr)
# library(lubridate)
# library(data.table)
# library(doMC); doMC::registerDoMC(cores = 7)
# ncDir <- "/home/amieroh/Documents/Data/Datasets/G1SST/daily"
# csvDir <- "/media/amieroh/Seagate Expansion Drive/Extracted G1SST"
# 
# # #          1         2         3         4
# # # 12345678901234567890123456789012345678901
# # # 20020601-JPL-L4UHfnd-GLOB-v01-fv04-MUR.nc
# #          1         2         3         4         5         6
# # 1234567890123456789012345678901234567890123456789012345678901
# # 20100609-JPL_OUROCEAN-L4UHfnd-GLOB-v01-fv01_0-G1SST_subset.nc
# 
# 
# # ncFile <- '/home/amieroh/Documents/Data/Datasets/MUR/daily/20020606-JPL-L4UHfnd-GLOB-v01-fv04-MUR.nc'
#   ncFun <- function(ncFile = ncFile, region = region, csvDir = csvDir) {
#     coords <- bbox[, region]
#     nc <- nc_open(ncFile)
#     pathLen <- nchar(paste0(ncDir, "/")) + 1
#     fNameStem <-
#       substr(basename(ncFile), 10, 58)
#     fDate <- substr(basename(ncFile), 1, 8)
#     LatIdx <- which(nc$dim$lat$vals > coords[1] & nc$dim$lat$vals < coords[2])
#     LonIdx <- which(nc$dim$lon$vals > coords[3] & nc$dim$lon$vals < coords[4])
#     sst <- ncvar_get(nc, varid = "analysed_sst") %>%
#       round(4)
#     dimnames(sst) <- list(lon = nc$dim$lon$vals,
#                           lat = nc$dim$lat$vals)
#     nc_close(nc)
#     sst <- as_tibble(melt(sst, value.name = "temp"))
#     sst$t <- ymd(fDate)
#     na.omit(sst)
#     fwrite(sst,
#            file = paste0(csvDir, "/", region, "-", fNameStem, "-", strtDate, "-", endDate, ".csv"),
#            append = TRUE, col.names = FALSE)
#     rm(sst)
#   }
# 
# 
#   ncList <- list.files(path = paste0(ncDir), pattern = "*.nc", full.names = TRUE, include.dirs = TRUE)
#   ncFirst <- head(list.files(path = paste0(ncDir, "/"), pattern = "*.nc", full.names = FALSE), 1)
#   ncLast <- tail(list.files(path = paste0(ncDir, "/"), pattern = "*.nc", full.names = FALSE), 1)
#   strtDate <- str_sub(ncFirst, start = 1, end = 8)
#   endDate <- str_sub(ncLast, start = 1, end = 8)
# 
# llply(ncList, ncFun, region = "BC", csvDir = csvDir, .parallel = TRUE)

```

# Using the upwelling metrics created in `upwell.IDX.Rmd` Identify when upwelling occurs at the particular site. 
# Is this upwelling event seen throughout the different distances from the coastline
# Using CMC, MUR, OISST and SACTN_US to determine wether the upwelling events detected are present in each of the datasets

## Function
Determining the temperatures at the various distances from the coastline

```{r}
# # These following three objects (MUR, OISST, CMC) need to be the complete set of lon/lat values for your satellite data
# MUR <- MUR %>%
#   select(lon, lat) %>%
#   mutate(product = "MUR")
# 
# # Decided to work with OISST and CMC as both has a time series of 30years
OISST_prod <- OISST %>%
  select(lon, lat) %>%
  unique() %>%
  mutate(product = "OISST")
# 
CMC_prod <- CMC %>%
  select(lon, lat) %>%
  unique() %>%
  mutate(product = "CMC")
# 
sat_data <- rbind(CMC_prod, OISST_prod) %>% 
#   #rbind(., CMC) %>% 
select(product, lon, lat)
# 
sat_pixels <- sat_data %>%
select(product, lon, lat) %>%
unique()
# 
# ## For testing the nest/map pipeline
# # df <- site_pixels %>%
# #   filter(site == "Lamberts Bay") %>%
# #   select(-site)
# 
match_func <- function(df){
  df <- df %>%
    dplyr::rename(lon_site = lon, lat_site = lat)
  OISST_index <- OISST_prod[as.vector(knnx.index(as.matrix(OISST_prod[,c("lon", "lat")]),
                                                 as.matrix(df[,c("lon_site", "lat_site")]), k = 1)),] %>%
    cbind(., df)
  CMC_index <- CMC_prod[as.vector(knnx.index(as.matrix(CMC_prod[,c("lon", "lat")]),
                                             as.matrix(df[,c("lon_site", "lat_site")]), k = 1)),] %>%
    cbind(., df)
  res <- rbind(OISST_index, CMC_index)
  return(res)
}

# # Find the nearest pixels to each spot along the transect
# # NB: SOme pixels are used more thanonce in a transect as the spacing isn't quite larger enough between transect
# # points to not fall inside of the same 25 KM pixel
pixel_match <- site_pixels %>%
  group_by(site) %>%
  group_modify(~match_func(.x))

# # You may then use the 'pixel_match' object to filter out the desired pixels from the full satellite products
OISST_fill <- right_join(OISST, filter(pixel_match, product == "OISST"), by = c("lon", "lat"))
CMC_fill <- right_join(CMC, filter(pixel_match, product == "CMC"), by = c("lon", "lat"))
# #SACTN_fill <- right_join(SACTN, filter(pixel_match, product == "SACTN"), by = c("lon", "lat"))
# 
# Clean up some RAM space
rm(OISST, CMC); gc()
# 
# # sites <- c("Port Nolloth", "Lamberts Bay", "Saldanha Bay", "Sea Point")
# # # In the SACTN dataset Hout Bay only has data until 2005. Hout Bay will now be removed from this study
# # # Hout Bay will be ignored
selected_sites <- c("Port Nolloth", "Lamberts Bay", "Sea Point", "Saldanha Bay")
# 
OISST_fill <- OISST_fill %>%
  filter(site %in% selected_sites)

CMC_fill <- CMC_fill %>%
  filter(site %in% selected_sites)
# 
# 
# # All the code below can be viewed in upwell_IDX.Rmd
# # Next to run upwelling index
# # UI Created using SAWS wind data (Find in upwell_IDX_Rmd)
# load("Data/UI_angle.RData")
# 
upwelling <- UI_angle %>%
  dplyr::rename(temp = ui.saws) %>%
  group_by(site) %>%
  # mutate(min_t = min(t),
  #        max_t = max(t)) %>%
  nest() %>% # apply the following functions to all of the variables in te dataset
  mutate(clim = purrr::map(data, ts2clm, climatologyPeriod = c("1997-01-01", "2015-12-31")), # creating a column of climatologies. Column will be named clim
         # NB: A threshold of 3 appeared to be far to strict
         # purr::map - apllies a function to each element of a vector
         exceed = purrr::map(clim, exceedance, minDuration = 1, threshold = 1)) %>%  #Upwelling cannot be descrbed as an event. Upwelling can last for a few hours. Given that we have daily data, upwelling events minimum duration here will be 1day
  # Detect consecutive days in exceedance of a given threshold.
  # mutate() %>%
  select(-data, -clim) %>%
  unnest() %>%
  filter(row_number() %% 2 == 1) %>%
  unnest() %>% # creates a column for each variables
  dplyr::rename(ui.saws = temp) %>% # rename upwelling index vale to temp so that it could work with the function
  select(site, t, ui.saws, exceedance)

# Now applying the Upwelling func
# NB: This only pulls out the event results and not the climatology results
# This is done to keep the output tidy because group_modify() may only create data.frame type outputs
# To create a list output one would use group_map(),
# but this then loses the labels of which sites etc. the results belong to
detect_event_custom <- function(df){
  res <- detect_event(df, threshClim2 = df$exceedance, minDuration = 1, coldSpells = T)$event # 1 or 3?
  return(res)
}
# 
ts2clm_custom <- function(df){
  # The climatology base period used here is up for debate...
  # The choice of the 25th percentile threshold also needs to be justified and sensitivty tested
  res <- ts2clm(df, pctile = 25, climatologyPeriod = c("1992-01-01", "2016-12-31"))
  return(res)
}
# 
# Calculate the upwelling event metrics
upwelling_detect_event <- function(df){
  upwell_base <- df %>%
    dplyr::rename(t = date) %>%
    group_by(site, product, heading, distance, lon, lat) %>%
    group_modify(~ts2clm_custom(.x)) %>%
    left_join(upwelling, by = c("site", "t")) %>%
    filter(!is.na(exceedance)) %>%
    group_by(site, product, heading, distance, lon, lat) %>%
    group_modify(~detect_event_custom(.x))
  }
# 
OISST_upwell_base <- upwelling_detect_event(df = OISST_fill)
save(OISST_upwell_base, file = "Data/OISST_upwell_base.RData")
CMC_upwell_base <- upwelling_detect_event(df = CMC_fill)
save(CMC_upwell_base, file = "Data/CMC_upwell_base.RData")
# 
# Here we remove the site Hout Bay so that we have a long time series. The length of Hout Bay time series ends in 200. Many sites change from here
SACTN_US <- SACTN_US %>%
  filter(site %in% selected_sites)

load("Data/site_list_v4.2.RData")

SACTN_upwell_base <- SACTN_US %>%
  left_join(site_list[,c(4, 5, 6)], by = "index")%>%
    dplyr::rename(t = date) %>%
    group_by(site, lon, lat) %>%
    group_modify(~ts2clm_custom(.x)) %>%
    left_join(upwelling, by = c("site", "t")) %>%
    filter(!is.na(exceedance)) %>%
    group_by(site, lon, lat) %>%
    group_modify(~detect_event_custom(.x))

save(SACTN_upwell_base, file = "Data/SACTN_upwell_base.RData")
```

Loading the data
    This is the data obtained once the upwelling signals were filtered out

```{r}
load("Data/OISST_upwell_base.RData")
load("Data/CMC_upwell_base.RData")
load("Data/SACTN_upwell_base.RData")
load("Data/MUR_upwell_base.RData")
load("Data/G1SST_upwell_base.RData")

# Removing the distance of 20 and 40kms
library(dplyr)
removing_distance_func <- function(df){
  removing_dist_func<- df %>% 
       filter(!distance %in% c(20000,40000))
}

OISST_final <- removing_distance_func(df = OISST_upwell_base)
G1SST_final <- removing_distance_func(df = G1SST_upwell_base)
MUR_final <- removing_distance_func(df = MUR_upwell_base)
CMC_final <- removing_distance_func(df = CMC_upwell_base)

# save(OISST_final, file = "Data/OISST_final.RData")
# save(G1SST_final, file = "Data/G1SST_final.RData")
# save(MUR_final, file = "Data/MUR_final.RData")
# save(CMC_final, file = "Data/CMC_final.RData")
```

To accurately compare 
  Start date CMC start date 1991-09-02 end date 2017-03-15
  Start date OISST start date 1981-09- 01  and end date 2018-09-28
  Start date SACTN start date 1973 and end date 2017-12-16
  
```{r}
#glm to determine if there is a difference in the number of events recorded at different at every distance

load("Data/Count/OISST_count.RData")
load("Data/Count/G1SST_count.RData")
load("Data/Count/MUR_count.RData")
load("Data/Count/CMC_count.RData")


options(scipen = 999)
anova_func <- function(df){
  sites_aov <- aov(distance ~ duration * site * site, data = df)
return(sites_aov)
}

OISST_anov <- anova_func(df = OISST_upwell_base)
summary(OISST_anov)
CMC_anov <- anova_func(df = CMC_upwell_base)
summary(CMC_anov)

MUR_anov <- anova_func(df = MUR_upwell_base)
summary(MUR_anov)

SACTN_anov <- aov(intensity_mean ~ site * duration, data = SACTN_upwell_base)
summary(SACTN_anov)




lm_coeff <- function(df){
  res <- lm(formula = val ~ date_peak, data = df)
  res_coeff <- round(as.numeric(res$coefficient[2]), 4)
}
# Changes in upwelling metrics
lm_func <- function(df){
  upwell_lm <- df %>% 
  select(-c(index_start:index_end)) %>% 
  gather(key = "var", value = "val", -c(site:date_end)) %>% 
  group_by(site, var, distance) %>% 
  nest() %>% 
  mutate(slope = purrr::map(data, lm_coeff)) %>% 
  select(-data) %>% 
  unnest() %>% 
  # convert from daily to decadal values
  mutate(slope = slope * 365.25*10)
}

OISST_lm <- lm_func(df = OISST_upwell_base)
CMC_lm <- lm_func(df = CMC_upwell_base)

SACTN_lm <- SACTN_upwell_base %>% 
  select(-c(index_start:index_end)) %>% 
  gather(key = "var", value = "val", -c(site:date_end)) %>% 
  group_by(site, var) %>% 
  nest() %>% 
  mutate(slope = purrr::map(data, lm_coeff)) %>% 
  select(-data) %>% 
  unnest() %>% 
  # convert from daily to decadal values
  mutate(slope = slope * 365.25*10)
```
  

As a common date we will use a start date from 1992-01-31 and end date 16-12-31

```{r}
# Generalosed linear models

# Generalized Linear Models- Look at the difference in metrics of in situ upwelling and remotely sensed SST data upwelling 
# Generalized linear models are fit using the glm( ) function. The form of the glm function is glm(formula, family=familytype(link=linkfunction), data=)

# trends_duration_func <- function(df){
#   upwellmodel <- glm(SACTN_upwell_base$duration[SACTN_upwell_base$event_no] ~ seq(1:length(SACTN_upwell_base$duration[SACTN_upwell_base$event_no])), 
#                      family = poisson(link = "log"))
#   upwellmodel0 <- glm(SACTN_upwell_base$duration[SACTN_upwell_base$event_no] ~ 1, family = poisson(link = "log")) # intercept only
#   dat2 <- data.frame(site = SACTN_upwell_base$site, upwelltrend = round(as.numeric(coef(upwellmodel)[2]*10),1),
#                        upwellR2 = round(1-logLik(upwellmodel)/logLik(upwellmodel0),2), # McFadden's pseudo-R2
#                        upwell.val = round(coef(summary(upwellmodel))[,4][2],2))
# }
# 
# OISST_trends_duration_func <- trends_duration_func(df = OISST_upwell_base)
# CMC_trends_duration_func <- trends_duration_func(df = CMC_upwell_base)
# SACTN_trends_duration_func <- trends_duration_func(df = SACTN_upwell_base)
# 
# 
# ### Intensity: Chnaged the family and link because of the negative values within the dataset 
# trends_intensity_func <- function(df){
#   upwellmodel <- glm(SACTN_upwell_base$intensity_mean[SACTN_upwell_base$event_no] ~ seq(1:length(SACTN_upwell_base$intensity_mean[SACTN_upwell_base$event_no])), 
#                      family = gaussian(link = "identity"))
#   upwellmodel0 <- glm(SACTN_upwell_base$intensity_mean[SACTN_upwell_base$event_no] ~ 1, family = gaussian(link = "identity")) # intercept only
#   dat2 <- data.frame(site = SACTN_upwell_base$site, upwelltrend = round(as.numeric(coef(upwellmodel)[2]*10),1),
#                        upwellR2 = round(1-logLik(upwellmodel)/logLik(upwellmodel0),2), # McFadden's psesudo-R2
#                        upwell.val = round(coef(summary(upwellmodel))[,4][2],2))
# }
# 
# OISST_trends_intensity_func <- trends_intensity_func(df = OISST_upwell_base)
# CMC_trends_intensity_func <- trends_intensity_func(df = CMC_upwell_base)
# SACTN_trends_intensity_func <- trends_intensity_func(df = SACTN_upwell_base)
```

# From the years 1992 - 2017

```{r}
# Which pixels showed the highest upwelling counts within the different datasets
# Which site showed the most intense upwelling within the different datasets

metric_func <- function(df){
 metrics <-df %>% 
  filter(year(date_start) %in% 1992:2017) %>% 
  #mutate(year = year(date_start)) %>% 
  group_by(distance, site) %>% 
  summarise(mean_intensity = mean(intensity_mean),
            sum_events = sum(event_no)) %>% 
   select(site, distance, mean_intensity, sum_events)
}

OISST_metrics <- metric_func(OISST_upwell_base)
CMC_metrics <- metric_func(CMC_upwell_base)

# No of u pwelling events found at the different sites
SACTN_metrics <- SACTN_upwell_base %>% 
  filter(year(date_start) %in% 1992:2017) %>% 
  group_by(site) %>% 
  summarise(mean_intensity = mean(intensity_mean),
            sum_events = sum(event_no)) %>% 
  select(site, mean_intensity, sum_events)

# Create a table showing these metrics


```

# Wind plots

```{r, fig.cap = "Windrose diagram representing the wind direction and speed for each of the sites", fig.height = 10, fig.width = 15}
library(ggradar)
library(dplyr)
library(scales)
library(tibble)
load("Data/UI_angle.RData")

# Detects NA values, no NA values are present
# Plotting wind variables
source("Functions/wind.rose.R") # This it may be related to the countmax = NA in the function

wind_daily_renamed <- UI_angle %>% 
  mutate(dir_circ = ifelse(dir_circ < 0, dir_circ+360, dir_circ)) %>% 
  dplyr::rename(spd = mean_speed) %>%
  dplyr::rename(dir = dir_circ) %>% 
  filter(spd > 0)

p.wr2 <- plot.windrose(data = wind_daily_renamed,
              spd = "spd",
              dir = "dir")

p.wr3 <- p.wr2 + facet_wrap(.~ site, ncol = 2, nrow = 2) +
  theme(strip.text.x = element_text(size = 25)) + theme(panel.spacing = unit(2, "lines"))
p.wr3

################3

# load("Data/UI_angle.RData")
# 
# wind_plot_prep <- UI_angle %>% 
#   select(-t, -ui.saws)
# 
# wind_plot <- wind_plot_prep %>% 
#   as_tibble(rownames = "site") %>% 
#   group_by(site) %>% 
#   mutate_at(vars(-site), rescale) %>% 
#   tail(4) 
# 
# ggradar(wind_plot)
# 
# ??countmax

```

# ANOVA
- Relationship between duration, year and site as a function of the distance 
The number of events per distance and then compare this at each distance 

```{r}
options(scipen = 999)
anova_func <- function(df){
  sites_aov <- aov(distance ~ duration * site * site, data = df)
return(sites_aov)
}

OISST_anov <- anova_func(df = OISST_upwell_base)
summary(OISST_anov)
CMC_anov <- anova_func(df = CMC_upwell_base)
summary(CMC_anov)

MUR_anov <- anova_func(df = MUR_upwell_base)
summary(MUR_anov)

SACTN_anov <- aov(intensity_mean ~ site * duration, data = SACTN_upwell_base)
summary(SACTN_anov)
```


Plot showing upwelling at the different sites for each of the different distances. Scatter plot

```{r}

load("Data/OISST_upwell_base.RData")
load("Data/CMC_upwell_base.RData")
load("Data/SACTN_upwell_base.RData")
load("Data/MUR_upwell_base.RData")
load("Data/G1SST_upwell_base.RData")

km_func <- function(df){
  upwell_base <-  df%>% 
      mutate(distance_km = case_when(distance == "10000" ~ "10",
                                    distance == "20000" ~ "20",
                                    distance  == "30000" ~"30",
                                    distance  == "40000" ~ "40",
                                    distance  == "50000" ~ "50"))
}
OISST_upwell_base <- km_func(df = OISST_upwell_base)
OISST_upwell_base$distance_km <- as.numeric(OISST_upwell_base$distance_km)

CMC_upwell_base <- km_func(df = CMC_upwell_base)
CMC_upwell_base$distance_km <- as.numeric(CMC_upwell_base$distance_km)

MUR_upwell_base <- km_func(df = MUR_upwell_base)
MUR_upwell_base$distance_km <- as.numeric(MUR_upwell_base$distance_km)

G1SST_upwell_base <- km_func(df = G1SST_upwell_base)
G1SST_upwell_base$distance_km <- as.numeric(G1SST_upwell_base$distance_km)

library(ggpubr)
year_func <- function(df){
  Filtered <- df %>%
filter(year(date_start) %in% seq(2011, 2013, 1))
}

CMC_filtered <- year_func(df = CMC_upwell_base)
OISST_filtered <- year_func(df = OISST_upwell_base)
SACTN_filtered <- year_func(df = SACTN_upwell_base)
MUR_filtered <- year_func(df = MUR_upwell_base)
G1SST_filtered <- year_func(df = G1SST_upwell_base)

CMC_SEAPOINT <- CMC_filtered %>% 
  filter(site == "Sea Point")
CMC_SB <- CMC_filtered %>% 
  filter(site == "Saldanha Bay")
CMC_PN <- CMC_filtered %>% 
  filter(site == "Port Nolloth")
CMC_LB <- CMC_filtered %>% 
  filter(site == "Lamberts Bay")

###################
## OISST
OISST_SEAPOINT <- OISST_filtered %>% 
  filter(site == "Sea Point")
OISST_SB <- OISST_filtered %>% 
  filter(site == "Saldanha Bay")
OISST_PN <- OISST_filtered %>% 
  filter(site == "Port Nolloth")
OISST_LB <- OISST_filtered %>% 
  filter(site == "Lamberts Bay")

############
#####MUR

MUR_SEAPOINT <- MUR_filtered %>% 
  filter(site == "Sea Point")
MUR_SB <- MUR_filtered %>% 
  filter(site == "Saldanha Bay")
MUR_PN <- MUR_filtered %>% 
  filter(site == "Port Nolloth")
MUR_LB <- MUR_filtered %>% 
  filter(site == "Lamberts Bay")
###########
####G1SST

G1SST_SEAPOINT <- G1SST_filtered %>% 
  filter(site == "Sea Point")
G1SST_SB <- G1SST_filtered %>% 
  filter(site == "Saldanha Bay")
G1SST_PN <- G1SST_filtered %>% 
  filter(site == "Port Nolloth")
G1SST_LB <- G1SST_filtered %>% 
  filter(site == "Lamberts Bay")

```

# Lolli plot

```{r}
plot_loli_func <- function(df){
  ggplot(df, aes(x = date_peak, y = duration)) + 
  geom_lolli(colour = "steelblue3", colour_n = "navy", n = 3) + 
  #scale_color_distiller(palette = "Spectral", name = "Cumulative \nintensity") + 
  facet_wrap(~distance_km, ncol = 2) +
  scale_y_continuous(breaks = c(5,10,15,20,25,30),
                     limits = c(1,30)) +
    scale_x_date(limits = as.Date(c("2011-01-01","2014-01-01"))) +
  theme_bw() +
  theme(axis.text=element_text(size=15),
        axis.title=element_text(size=17)) +
  theme(strip.text.x = element_text(size = 17))+
  theme(panel.spacing = unit(1, "lines")) +
    #theme(strip.text = c("10km", "20km", "30km", "40km", "50km")) +
  #strip=strip.custom(var.name=c("10km", "20km", "30km", "40km", "50km")) +
  xlab("Date (years)") + ylab("Event duration (days)") 
}


(OISST_SP_pl <- plot_loli_func(df = OISST_SEAPOINT))
(OISST_SB_pl <- plot_loli_func(df = OISST_SB))
(OISST_PN_pl <- plot_loli_func(df = OISST_PN))
(OISST_LB_pl <- plot_loli_func(df = OISST_LB))

OISST_SP_pl <- OISST_SP_pl +
  ggtitle("D.") #Sea Point
OISST_SB_pl <- OISST_SB_pl +
  ggtitle("C.") # Saldanha Bay
OISST_PN_pl <- OISST_PN_pl +
  ggtitle("B.")        # Port Nolloth
OISST_LB_pl <- OISST_LB_pl +
  ggtitle("A.")#Lamberts Bay

combined_OISST_pl_2 <- ggarrange(OISST_SB_pl, OISST_SP_pl) 

combined_OISST_pl_1 <- ggarrange(OISST_LB_pl, OISST_PN_pl)

#######
# CMC

(CMC_SP_pl <- plot_loli_func(df = CMC_SEAPOINT))
(CMC_SB_pl <- plot_loli_func(df = CMC_SB))
(CMC_PN_pl <- plot_loli_func(df = CMC_PN))
(CMC_LB_pl <- plot_loli_func(df = CMC_LB))

CMC_SP_pl <- CMC_SP_pl +
  ggtitle("D.") #Sea Point
CMC_SB_pl <- CMC_SB_pl +
  ggtitle("C.") # Saldanha Bay
CMC_PN_pl <- CMC_PN_pl +
  ggtitle("B.")        # Port Nolloth
CMC_LB_pl <- CMC_LB_pl +
  ggtitle("A.")#Lamberts Bay

combined_CMC_pl_2 <- ggarrange(CMC_SB_pl, CMC_SP_pl) 

combined_CMC_pl_1 <- ggarrange(CMC_LB_pl, CMC_PN_pl)

##########
### MUR
(MUR_SP_pl <- plot_loli_func(df = MUR_SEAPOINT))
(MUR_SB_pl <- plot_loli_func(df = MUR_SB))
(MUR_PN_pl <- plot_loli_func(df = MUR_PN))
(MUR_LB_pl <- plot_loli_func(df = MUR_LB))


MUR_SP_pl <- MUR_SP_pl +
  ggtitle("D.") #Sea Point
MUR_SB_pl <- MUR_SB_pl +
  ggtitle("C.") # Saldanha Bay
MUR_PN_pl <- MUR_PN_pl +
  ggtitle("B.")        # Port Nolloth
MUR_LB_pl <- MUR_LB_pl +
  ggtitle("A.")#Lamberts Bay


combined_MUR_pl_2 <- ggarrange(MUR_SB_pl, MUR_SP_pl) 

combined_MUR_pl_1 <- ggarrange(MUR_LB_pl, MUR_PN_pl)
#######
#G1SST

(G1SST_SP_pl <- plot_loli_func(df = G1SST_SEAPOINT))
(G1SST_SB_pl <- plot_loli_func(df = G1SST_SB))
(G1SST_PN_pl <- plot_loli_func(df = G1SST_PN))
(G1SST_LB_pl <- plot_loli_func(df = G1SST_LB))

G1SST_SP_pl <- G1SST_SP_pl +
  ggtitle("D.") #Sea Point
G1SST_SB_pl <- G1SST_SB_pl +
  ggtitle("C.") # Saldanha Bay
G1SST_PN_pl <- G1SST_PN_pl +
  ggtitle("B.")        # Port Nolloth
G1SST_LB_pl <- G1SST_LB_pl +
  ggtitle("A.")#Lamberts Bay

combined_G1SST_pl_2 <- ggarrange(G1SST_SB_pl, G1SST_SP_pl) 

combined_G1SST_pl_1 <- ggarrange(G1SST_LB_pl, G1SST_PN_pl)

########

plot_loli_func <- function(df){
  ggplot(df, aes(x = date_peak, y = duration)) + 
  geom_lolli(colour = "steelblue3", colour_n = "navy", n = 3) + 
  #scale_color_distiller(palette = "Spectral", name = "Cumulative \nintensity") + 
   facet_wrap(~site, ncol = 2) +
  scale_y_continuous(breaks = c(5,10,15,20,25,30),
                     limits = c(1,30)) +
  theme_bw() +
  theme(axis.text=element_text(size=17),
        axis.title=element_text(size=17)) +
  theme(strip.text.x = element_text(size = 17))+
  theme(panel.spacing = unit(0.5, "lines")) +
  #strip=strip.custom(var.name=c("10km", "20km", "30km", "40km", "50km")) +
  xlab("Date (years)") + ylab("Event duration (days)") 
}

(SACTN_plot <- plot_loli_func(df = SACTN_filtered))
```

# GLM - Determining if a change occur in the number of signals detected at different distances from the coastline
# Included a table in the paper
  Table discuss/count the number of upwelling signals detected at the different distances
  
  - For some of the sites it is seen that fewer upwelling signals are visible at a further distance from the coastline
  - When adding up all the signals observed at their respective distance it is seen that there are only slight differences in the amount of signals detected In some cases the signals detected at 10km from the coastline exceed that detected at 50km and visa versa

## Number of events detected

Using the start date and getting the month and year into a column. The month and year will be on the xaxis
Then count the number of times per month at different years signals are detected

```{r}
load("Data/OISST_final.RData")
load("Data/CMC_final.RData")
load("Data/SACTN_upwell_base.RData")
load("Data/MUR_final.RData")
load("Data/G1SST_final.RData")

knitr::opts_chunk$set(
  comment = "R>",
  warning = FALSE,
  message = FALSE 
)
#update.packages() 
library(tidyverse)
library(lubridate)
library(ggpubr)
library(zoo)
library(FNN)
library(scales)
library(gridExtra)
library(circular)
library(fossil)
library(mapproj)
library(broom)
# library(ncdf4) # This was used to process NetCDF files in an earlier version
library(stringr)
library(doMC); doMC::registerDoMC(cores = 4)
library(fasttime)
library(xtable)
library(ncdf4) # library for processing netCDFs
library(data.table)
# library(plyr) # RWS: Never load the plyr package as it interferes with the tidyverse
library(heatwaveR)
```

# Loading in all the data created using the code bellow

```{r}
load("Data/site_list_sub.Rdata")
load("Data/SACTN_US.RData")
load("Data/site_pixels.RData") # 5 decimal places
load("Data/OISST.RData") # 2 decimal places
OISST <- BC_avhrr_only_v2_Document_Document 
rm(BC_avhrr_only_v2_Document_Document ); gc()
load("Data/CMC.RData") # 1decimal places
```

```{r}
# SACTN_US <- SACTN_US %>% 
#   dplyr::rename(in_situ_temp = temp)
# 
# # Visualising the data
# temp_plot <- function(df){
#   plot <- ggplot(data = df, aes(x = date, y = in_situ_temp, colour = site)) +
#     geom_line(aes(group = site)) +
#     labs(x = "", y = "Temperature (°C)") +
#     theme(axis.text.x = element_text(angle = 45)) +
#     theme(legend.position = "top")
# }
# 
# SACTN_plot <- temp_plot(df = SACTN_US)
# SACTN_plot


# 25th quantile
```

Different distances from the coastline

```{r}
# load("Data/site_list_sub.Rdata")
# # xtable(site_list_sub, auto = TRUE)
# west <- site_list_sub
# west$coast <- "west" # Chnages wc to west
# 
# load("Data/africa_coast.RData")
# 
# ## Downloading the bathy data from NOAA
# # Download mid-res bathymetry data
# # sa_lat <- c(-38, -24.5); sa_lon <- c(11.5, 35.5)
# # sa_bathy <- as.xyz(getNOAA.bathy(lon1 = sa_lon[1], lon2 = sa_lon[2], lat1 = sa_lat[1], lat2 = sa_lat[2], resolution = 4))
# # colnames(sa_bathy) <- c("lon", "lat", "depth")
# # sa_bathy <- sa_bathy[sa_bathy$depth <= 0,]
# # save(sa_bathy, file = "Data_P1/bathy/sa_bathy.RData")
# 
# # Loading in the newly downloaded bathymetry data               
# load("Data/bathy/sa_bathy.RData")

# # This function takes one site (e.g. one set of lon/lats) and calculates a shore normal transect
# shore.normal.transect <- function(site, width = 2){
#   # Find the site on the coastline and it's nearest neighbour points
#   coords <- data.frame(lon = site$lon, lat = site$lat)
#   coords2 <- knnx.index(africa_coast[,1:2], as.matrix(coords), k = 1)
#   coords3 <- data.frame(site = site$site, africa_coast[c(coords2-width, coords2+width),]) 
#   coords3 <- coords3[2:1,1:3]
#   # Define the shore normal transect bearing
#   heading <- earth.bear(coords3[1,2], coords3[1,3], coords3[2,2], coords3[2,3]) + 90
#   if(heading >= 360){
#     heading <- heading-360
#   } else {
#     heading <- heading
#   }
#   heading2 <- data.frame(site = site$site, lon = site$lon, lat = site$lat, heading)
#   return(heading2)
# }
# 
# # Creating the transects
# site_transects <- data.frame()
# for(i in 1:length(west$site)){
#  site <- west[i,]
#  site_transect <- shore.normal.transect(site, 2)
#  site_transects <- rbind(site_transects, site_transect)
# }
# 
# # Manually correcting Sea Point and Kommetjie
# site_transects$heading[4:5] <- 290 
# # save(site_transects, file = "Data/site_transects.RData")
# load("Data/site_transects.RData")
# 
# # This function takes one site (e.g. one set of lon/lats) and calculates a shore norm./subal transect
# # It then extracts a lat/ lon point every X kilometres until reaching a specified isobath
# 
# transect.pixel <- function(site, distances){
#   # Extract coordinates
#   coords <- data.frame(lon = site$lon, lat = site$lat)
#   # Find lon/ lats every X metres 
#   pixels <- data.frame()
#   # deep <- 999
#   # distance_multiplier <- 1
#   # while(deep > isobath){
#   for(i in 1:length(distances)){
#     coords2 <- as.data.frame(destPoint(p = coords, b = site$heading, d = distances[i]))
#     sitesIdx <- knnx.index(sa_bathy[,1:2], as.matrix(coords2), k = 1)
#     bathy2 <- sa_bathy[sitesIdx,]
#     bathy2 <- bathy2[complete.cases(bathy2$depth),]
#     bathy3 <- data.frame(site = site$site, lon = bathy2$lon, lat = bathy2$lat, 
#                          heading = site$heading, 
#                          distance = distances[i])
#     pixels <- rbind(pixels, bathy3)
#     coords <- coords2
#   }
#   if(nrow(pixels) < 1){
#     pixels <- data.frame(site, depth = NA)
#   }else{
#     pixels <- pixels
#   }+

#   return(pixels)
# }
# 
# # Pixel points
# site_pixels <- data.frame()
# for(i in 1:length(west$site)){
#   site <- site_transects[i,]
#   site_pixel <- transect.pixel(site, c(10000, 20000, 30000, 40000, 50000)) # RWS: fixed error
#   site_pixels <- rbind(site_pixels, site_pixel)
# }
# 
# # Bounding box
#   # Only one is made in order to know how large the the geom_point() squares should be made to match
# bbox <- data.frame(xmin = destPoint(p = site_pixels[1,2:3], b = 270, d = 12500)[1],
#                    xmax = destPoint(p = site_pixels[1,2:3], b = 90, d = 12500)[1],
#                    ymin = destPoint(p = site_pixels[1,2:3], b = 180, d = 12500)[2],
#                    ymax = destPoint(p = site_pixels[1,2:3], b = 0, d = 12500)[2])
# 
# # Determining the temperature at the various distances from the coast
# 
# # save(site_pixels, file = "Data/site_pixels.RData")
# load("Data/site_pixels.RData")


```

# Extrcting the MUR data

```{r}
# library(stringr)
# library(tidyverse)
# library(reshape2)
# library(ncdf4) # library for processing netCDFs
# library(plyr)
# library(lubridate)
# library(data.table)
# library(doMC); doMC::registerDoMC(cores = 7)
# 
# ncDir <- "/home/amieroh/Documents/Data/Datasets/MUR/daily"
# csvDir <- "/media/amieroh/Seagate Expansion Drive/Extracted G1SST/MUR_extracted"
# 
# #          1         2         3         4
# # 12345678901234567890123456789012345678901
# # 20020601-JPL-L4UHfnd-GLOB-v01-fv04-MUR.nc
# 
# read_nc <- function(ncDir = ncDir, csvDir = csvDir)
#   ncList <- list.files(path = paste0(ncDir), pattern = "*.nc", full.names = TRUE, include.dirs = TRUE)
#   ncFirst <- head(list.files(path = paste0(ncDir, "/"), pattern = "*.nc", full.names = FALSE), 1)
#   ncLast <- tail(list.files(path = paste0(ncDir, "/"), pattern = "*.nc", full.names = FALSE), 1)
#   strtDate <- str_sub(ncFirst, start = 1, end = 8)
#   endDate <- str_sub(ncLast, start = 1, end = 8)
# 
# # ncFile <- '/home/amieroh/Documents/Data/Datasets/MUR/daily/20020606-JPL-L4UHfnd-GLOB-v01-fv04-MUR.nc'
# 
#   ncFun <- function(ncFile = ncFile, csvDir = csvDir) {
#     nc <- nc_open(ncFile)
#     pathLen <- nchar(paste0(ncDir, "/")) + 1
# fNameStem <-
#   substr(basename(ncFile), 10, 38)
#     fDate <- substr(basename(ncFile), 1, 8)
#     sst <- ncvar_get(nc, varid = "analysed_sst") %>%
#       round(4)
#     dimnames(sst) <- list(lon = nc$dim$lon$vals,
#                           lat = nc$dim$lat$vals)
#     nc_close(nc)
#     sst <- as_tibble(melt(sst, value.name = "temp"))
#     sst$t <- ymd(fDate)
#     na.omit(sst)
#     fwrite(sst,
#            file = paste0(csvDir, "/", fNameStem, "-", strtDate, "-", endDate, ".csv"),
#            append = TRUE, col.names = FALSE)
#     rm(sst)
#   }
# 
# llply(ncList, ncFun, csvDir = csvDir, .parallel = TRUE)

# MUR <- read_csv("/home/amieroh/Documents/Data/Datasets/MUR/Extracted_MUR/BC-JPL-L4UHfnd-GLOB-v01-fv04-MUR-20020601-20140727.csv")
# names(MUR)<-c("lon","lat", "temp", "date")
# MUR <- MUR %>% 
#   mutate(temp = temp - 273.15)
# 
# JPL_L4UHfnd_GLOB_v01_fv04_MUR_20020601_20140727 <- read_csv("~/Documents/JPL-L4UHfnd-GLOB-v01-fv04-MUR-20020601-20140727.csv")
# 
# ######################################### SUBSET VIA REGION #################
# 
# # bbox <- data.frame(BC = c(-35, -25, 15, 20), # Benguela Current
# library(stringr)
# library(tidyverse)
# library(reshape2)
# library(ncdf4) # library for processing netCDFs
# library(plyr)
# library(lubridate)
# library(data.table)
# library(doMC); doMC::registerDoMC(cores = 7)
# ncDir <- "/home/amieroh/Documents/Data/Datasets/MUR/daily"
# csvDir <- "/home/amieroh/Documents/Data/Datasets/MUR/Extracted_MUR"
# #          1         2         3         4
# # 12345678901234567890123456789012345678901
# # 20020601-JPL-L4UHfnd-GLOB-v01-fv04-MUR.nc
# 
# # ncFile <- '/home/amieroh/Documents/Data/Datasets/MUR/daily/20020606-JPL-L4UHfnd-GLOB-v01-fv04-MUR.nc'
#   ncFun <- function(ncFile = ncFile, region = region, csvDir = csvDir) {
#     coords <- bbox[, region]
#     nc <- nc_open(ncFile)
#     pathLen <- nchar(paste0(ncDir, "/")) + 1
#     fNameStem <-
#       substr(basename(ncFile), 10, 38)
#     fDate <- substr(basename(ncFile), 1, 8)
#     LatIdx <- which(nc$dim$lat$vals > coords[1] & nc$dim$lat$vals < coords[2])
#     LonIdx <- which(nc$dim$lon$vals > coords[3] & nc$dim$lon$vals < coords[4])
#     sst <- ncvar_get(nc, varid = "analysed_sst") %>%
#       round(4)
#     dimnames(sst) <- list(lon = nc$dim$lon$vals,
#                           lat = nc$dim$lat$vals)
#     nc_close(nc)
#     sst <- as_tibble(melt(sst, value.name = "temp"))
#     sst$t <- ymd(fDate)
#     na.omit(sst)
#     fwrite(sst,
#            file = paste0(csvDir, "/", region, "-", fNameStem, "-", strtDate, "-", endDate, ".csv"),
#            append = TRUE, col.names = FALSE)
#     rm(sst)
#   }
#   
#   
#   ncList <- list.files(path = paste0(ncDir), pattern = "*.nc", full.names = TRUE, include.dirs = TRUE)
#   ncFirst <- head(list.files(path = paste0(ncDir, "/"), pattern = "*.nc", full.names = FALSE), 1)
#   ncLast <- tail(list.files(path = paste0(ncDir, "/"), pattern = "*.nc", full.names = FALSE), 1)
#   strtDate <- str_sub(ncFirst, start = 1, end = 8)
#   endDate <- str_sub(ncLast, start = 1, end = 8)  
#   
# llply(ncList, ncFun, region = "BC", csvDir = csvDir, .parallel = TRUE)
```

# Extracting the CMC data

```{r}
# ncDir <- "/home/amieroh/Documents/Data/Datasets/CMC/CMC_BC"
# csvDir <- "/home/amieroh/Documents/Data/Datasets/CMC/CMC_extracted"
# 
# #          1         2         3         4         5         6
# # 123456789012345678901234567890123456789012345678901234567890
# # 20100609-JPL_OUROCEAN-L4UHfnd-GLOB-v01-fv01_0-G1SST_subset.nc
# read_nc <- function(ncDir = ncDir, csvDir = csvDir) 
#   ncList <- list.files(path = paste0(ncDir), pattern = "*.nc", full.names = TRUE, include.dirs = TRUE)
#   ncFirst <- head(list.files(path = paste0(ncDir, "/"), pattern = "*.nc", full.names = FALSE), 1)
#   ncLast <- tail(list.files(path = paste0(ncDir, "/"), pattern = "*.nc", full.names = FALSE), 1)
#   strtDate <- str_sub(ncFirst, start = 1, end = 8)
#   endDate <- str_sub(ncLast, start = 1, end = 8)
# 
# # ncFile <- '/home/amieroh/Documents/Data/Datasets/CMC/CMC_BC/20100609-JPL_OUROCEAN-L4UHfnd-GLOB-v01-fv01_0-G1SST_subset.nc'
# 
#   ncFun <- function(ncFile = ncFile, csvDir = csvDir) {
#     nc <- nc_open(ncFile)
#     pathLen <- nchar(paste0(ncDir, "/")) + 1
#     fNameStem <-
#       substr(basename(ncFile), 10, 58)
#     fDate <- substr(basename(ncFile), 1, 8)
#     sst <- ncvar_get(nc, varid = "analysed_sst") %>%
#       round(4)
#     dimnames(sst) <- list(lon = nc$dim$lon$vals,
#                           lat = nc$dim$lat$vals)
#     nc_close(nc)
#     sst <- as_tibble(melt(sst, value.name = "temp"))
#     sst$t <- ymd(fDate)
#     na.omit(sst)
#     fwrite(sst,
#            file = paste0(csvDir, "/", fNameStem, "-", strtDate, "-", endDate, ".csv"),
#            append = TRUE, col.names = FALSE)
#     rm(sst)
#   }
# 
# llply(ncList, ncFun, csvDir = csvDir, .parallel = TRUE)
# 
# 
# CMC <- read_csv("/home/amieroh/Documents/Data/Datasets/CMC/CMC_extracted/Benguela_current/20000-CMC-L4_GHRSST-SSTfnd-CMC0.2deg-GLOB-v02.0-f-19910901-20170317.csv")
# names(CMC)<-c("lon","lat", "temp", "date")
# CMC <- CMC %>% 
#   mutate(temp = temp - 273.15)
# 
# # save(CMC, file = "Data/CMC.RData")
```

# Extracting the OISST data

```{r}
# bbox <- data.frame(BC = c(-35, -25, 15, 20), # Benguela Current
#                    CC = c(25, 35, 340, 355), # Canary Current
#                    CalC = c(35, 45, 225, 240), # California Current
#                    HC = c(-17.5, -7.5, 275, 290), # Humboldt Current
#                    row.names = c("latmin", "latmax", "lonmin", "lonmax"))
# 
# OISST.dir <- "/home/amieroh/Documents/Data/Datasets/OISSTv2/daily/netCDF/avhrr-only"
# OISST.csv.dir <- "/home/amieroh/Documents/Data/Datasets/OISST_subset"
# 
# #          1         2
# # 1234567890123456789012345
# # avhrr-only-v2.19810901.nc
# 
# # function to extract the dims and data from OISST netCDFs
# read_nc <- function(ncFile, region = region, csvDir = csvDir) {
#   coords <- bbox[, region]
#   nc <- nc_open(ncFile)
#   pathLen <- nchar(OISST.dir) + 1 # to account for the "/" that needs to be inserted
#   fNameStem <-
#     substr(ncFile, pathLen + 1, pathLen + 13)
#   fDate <- substr(ncFile, pathLen + 15, pathLen + 22)
#   LatIdx <- which(nc$dim$lat$vals > coords[1] & nc$dim$lat$vals < coords[2])
#   LonIdx <- which(nc$dim$lon$vals > coords[3] & nc$dim$lon$vals < coords[4])
#   sst <- ncvar_get(nc,
#                    varid = "sst",
#                    start = c(LonIdx[1], LatIdx[1], 1, 1),
#                    count = c(length(LonIdx), length(LatIdx), 1, 1)) %>%
#     round(4)
#   dimnames(sst) <- list(lon = nc$dim$lon$vals[LonIdx],
#                         lat = nc$dim$lat$vals[LatIdx])
#   nc_close(nc)
#   sst <-
#     as.data.table(melt(sst, value.name = "temp"), row.names = NULL) %>%
#     mutate(t = ymd(fDate)) %>%
#     na.omit()
#   fwrite(sst,
#          file = paste(csvDir, "/", region, "-", fNameStem, ".", strtDate, "-", endDate, ".csv", sep = ""),
#          append = TRUE, col.names = FALSE)
#   rm(sst)
# }
# 
# # the list of files
# ncList <- list.files(path = OISST.dir, pattern = "*.nc", full.names = TRUE, include.dirs = TRUE)
# strtDate <- str_sub(ncList[1], start = 15, end = 22)
# endDate <- str_sub(ncList[length(ncList)], start = 15, end = 22)
# 
# # apply the function
# system.time(llply(ncList, read_nc, region = "BC", csvDir = OISST.csv.dir, .parallel = TRUE))
# # system.time(llply(ncList, read_nc, region = "CC", csvDir = OISST.csv.dir, .parallel = TRUE))
# # system.time(llply(ncList, read_nc, region = "CalC", csvDir = OISST.csv.dir, .parallel = TRUE))
# # system.time(llply(ncList, read_nc, region = "HC", csvDir = OISST.csv.dir, .parallel = TRUE))
# 
# # Loading the data
# BC_avhrr_only_v2_Document_Document <- read_csv("~/Documents/OISST_subset/BC-avhrr-only-v2.Document-Document.csv" )
# names(BC_avhrr_only_v2_Document_Document)<-c("lon","lat", "temp", "date")
# 
# # Saving the data
# save(BC_avhrr_only_v2_Document_Document, file = "Data/OISST.RData")
```

# Extracting G1SST

```{r}
# bbox <- data.frame(BC = c(-35, -25, 15, 20)) # Benguela Current
# library(stringr)
# library(tidyverse)
# library(reshape2)
# library(ncdf4) # library for processing netCDFs
# library(plyr)
# library(lubridate)
# library(data.table)
# library(doMC); doMC::registerDoMC(cores = 7)
# ncDir <- "/home/amieroh/Documents/Data/Datasets/G1SST/daily"
# csvDir <- "/media/amieroh/Seagate Expansion Drive/Extracted G1SST"
# 
# # #          1         2         3         4
# # # 12345678901234567890123456789012345678901
# # # 20020601-JPL-L4UHfnd-GLOB-v01-fv04-MUR.nc
# #          1         2         3         4         5         6
# # 1234567890123456789012345678901234567890123456789012345678901
# # 20100609-JPL_OUROCEAN-L4UHfnd-GLOB-v01-fv01_0-G1SST_subset.nc
# 
# 
# # ncFile <- '/home/amieroh/Documents/Data/Datasets/MUR/daily/20020606-JPL-L4UHfnd-GLOB-v01-fv04-MUR.nc'
#   ncFun <- function(ncFile = ncFile, region = region, csvDir = csvDir) {
#     coords <- bbox[, region]
#     nc <- nc_open(ncFile)
#     pathLen <- nchar(paste0(ncDir, "/")) + 1
#     fNameStem <-
#       substr(basename(ncFile), 10, 58)
#     fDate <- substr(basename(ncFile), 1, 8)
#     LatIdx <- which(nc$dim$lat$vals > coords[1] & nc$dim$lat$vals < coords[2])
#     LonIdx <- which(nc$dim$lon$vals > coords[3] & nc$dim$lon$vals < coords[4])
#     sst <- ncvar_get(nc, varid = "analysed_sst") %>%
#       round(4)
#     dimnames(sst) <- list(lon = nc$dim$lon$vals,
#                           lat = nc$dim$lat$vals)
#     nc_close(nc)
#     sst <- as_tibble(melt(sst, value.name = "temp"))
#     sst$t <- ymd(fDate)
#     na.omit(sst)
#     fwrite(sst,
#            file = paste0(csvDir, "/", region, "-", fNameStem, "-", strtDate, "-", endDate, ".csv"),
#            append = TRUE, col.names = FALSE)
#     rm(sst)
#   }
# 
# 
#   ncList <- list.files(path = paste0(ncDir), pattern = "*.nc", full.names = TRUE, include.dirs = TRUE)
#   ncFirst <- head(list.files(path = paste0(ncDir, "/"), pattern = "*.nc", full.names = FALSE), 1)
#   ncLast <- tail(list.files(path = paste0(ncDir, "/"), pattern = "*.nc", full.names = FALSE), 1)
#   strtDate <- str_sub(ncFirst, start = 1, end = 8)
#   endDate <- str_sub(ncLast, start = 1, end = 8)
# 
# llply(ncList, ncFun, region = "BC", csvDir = csvDir, .parallel = TRUE)

```

# Using the upwelling metrics created in `upwell.IDX.Rmd` Identify when upwelling occurs at the particular site. 
# Is this upwelling event seen throughout the different distances from the coastline
# Using CMC, MUR, OISST and SACTN_US to determine wether the upwelling events detected are present in each of the datasets

## Function
Determining the temperatures at the various distances from the coastline

```{r}
# # These following three objects (MUR, OISST, CMC) need to be the complete set of lon/lat values for your satellite data
# MUR <- MUR %>%
#   select(lon, lat) %>%
#   mutate(product = "MUR")
# 
# # Decided to work with OISST and CMC as both has a time series of 30years
OISST_prod <- OISST %>%
  select(lon, lat) %>%
  unique() %>%
  mutate(product = "OISST")
# 
CMC_prod <- CMC %>%
  select(lon, lat) %>%
  unique() %>%
  mutate(product = "CMC")
# 
sat_data <- rbind(CMC_prod, OISST_prod) %>% 
#   #rbind(., CMC) %>% 
select(product, lon, lat)
# 
sat_pixels <- sat_data %>%
select(product, lon, lat) %>%
unique()
# 
# ## For testing the nest/map pipeline
# # df <- site_pixels %>%
# #   filter(site == "Lamberts Bay") %>%
# #   select(-site)
# 
match_func <- function(df){
  df <- df %>%
    dplyr::rename(lon_site = lon, lat_site = lat)
  OISST_index <- OISST_prod[as.vector(knnx.index(as.matrix(OISST_prod[,c("lon", "lat")]),
                                                 as.matrix(df[,c("lon_site", "lat_site")]), k = 1)),] %>%
    cbind(., df)
  CMC_index <- CMC_prod[as.vector(knnx.index(as.matrix(CMC_prod[,c("lon", "lat")]),
                                             as.matrix(df[,c("lon_site", "lat_site")]), k = 1)),] %>%
    cbind(., df)
  res <- rbind(OISST_index, CMC_index)
  return(res)
}

# # Find the nearest pixels to each spot along the transect
# # NB: SOme pixels are used more thanonce in a transect as the spacing isn't quite larger enough between transect
# # points to not fall inside of the same 25 KM pixel
pixel_match <- site_pixels %>%
  group_by(site) %>%
  group_modify(~match_func(.x))

# # You may then use the 'pixel_match' object to filter out the desired pixels from the full satellite products
OISST_fill <- right_join(OISST, filter(pixel_match, product == "OISST"), by = c("lon", "lat"))
CMC_fill <- right_join(CMC, filter(pixel_match, product == "CMC"), by = c("lon", "lat"))
# #SACTN_fill <- right_join(SACTN, filter(pixel_match, product == "SACTN"), by = c("lon", "lat"))
# 
# Clean up some RAM space
rm(OISST, CMC); gc()
# 
# # sites <- c("Port Nolloth", "Lamberts Bay", "Saldanha Bay", "Sea Point")
# # # In the SACTN dataset Hout Bay only has data until 2005. Hout Bay will now be removed from this study
# # # Hout Bay will be ignored
selected_sites <- c("Port Nolloth", "Lamberts Bay", "Sea Point", "Saldanha Bay")
# 
OISST_fill <- OISST_fill %>%
  filter(site %in% selected_sites)

CMC_fill <- CMC_fill %>%
  filter(site %in% selected_sites)
# 
# 
# # All the code below can be viewed in upwell_IDX.Rmd
# # Next to run upwelling index
# # UI Created using SAWS wind data (Find in upwell_IDX_Rmd)
# load("Data/UI_angle.RData")
# 
upwelling <- UI_angle %>%
  dplyr::rename(temp = ui.saws) %>%
  group_by(site) %>%
  # mutate(min_t = min(t),
  #        max_t = max(t)) %>%
  nest() %>% # apply the following functions to all of the variables in te dataset
  mutate(clim = purrr::map(data, ts2clm, climatologyPeriod = c("1997-01-01", "2015-12-31")), # creating a column of climatologies. Column will be named clim
         # NB: A threshold of 3 appeared to be far to strict
         # purr::map - apllies a function to each element of a vector
         exceed = purrr::map(clim, exceedance, minDuration = 1, threshold = 1)) %>%  #Upwelling cannot be descrbed as an event. Upwelling can last for a few hours. Given that we have daily data, upwelling events minimum duration here will be 1day
  # Detect consecutive days in exceedance of a given threshold.
  # mutate() %>%
  select(-data, -clim) %>%
  unnest() %>%
  filter(row_number() %% 2 == 1) %>%
  unnest() %>% # creates a column for each variables
  dplyr::rename(ui.saws = temp) %>% # rename upwelling index vale to temp so that it could work with the function
  select(site, t, ui.saws, exceedance)

# Now applying the Upwelling func
# NB: This only pulls out the event results and not the climatology results
# This is done to keep the output tidy because group_modify() may only create data.frame type outputs
# To create a list output one would use group_map(),
# but this then loses the labels of which sites etc. the results belong to
detect_event_custom <- function(df){
  res <- detect_event(df, threshClim2 = df$exceedance, minDuration = 3, coldSpells = T)$event
  return(res)
}
# 
ts2clm_custom <- function(df){
  # The climatology base period used here is up for debate...
  # The choice of the 25th percentile threshold also needs to be justified and sensitivty tested
  res <- ts2clm(df, pctile = 25, climatologyPeriod = c("1992-01-01", "2016-12-31"))
  return(res)
}
# 
# Calculate the upwelling event metrics
upwelling_detect_event <- function(df){
  upwell_base <- df %>%
    dplyr::rename(t = date) %>%
    group_by(site, product, heading, distance, lon, lat) %>%
    group_modify(~ts2clm_custom(.x)) %>%
    left_join(upwelling, by = c("site", "t")) %>%
    filter(!is.na(exceedance)) %>%
    group_by(site, product, heading, distance, lon, lat) %>%
    group_modify(~detect_event_custom(.x))
  }
# 
OISST_upwell_base <- upwelling_detect_event(df = OISST_fill)
save(OISST_upwell_base, file = "Data/OISST_upwell_base.RData")
CMC_upwell_base <- upwelling_detect_event(df = CMC_fill)
save(CMC_upwell_base, file = "Data/CMC_upwell_base.RData")
# 
# Here we remove the site Hout Bay so that we have a long time series. The length of Hout Bay time series ends in 200. Many sites change from here
SACTN_US <- SACTN_US %>%
  filter(site %in% selected_sites)

load("Data/site_list_v4.2.RData")

SACTN_upwell_base <- SACTN_US %>%
  left_join(site_list[,c(4, 5, 6)], by = "index")%>%
    dplyr::rename(t = date) %>%
    group_by(site, lon, lat) %>%
    group_modify(~ts2clm_custom(.x)) %>%
    left_join(upwelling, by = c("site", "t")) %>%
    filter(!is.na(exceedance)) %>%
    group_by(site, lon, lat) %>%
    group_modify(~detect_event_custom(.x))

save(SACTN_upwell_base, file = "Data/SACTN_upwell_base.RData")
```

Loading the data
    This is the data obtained once the upwelling signals were filtered out

```{r}
load("Data/OISST_upwell_base.RData")
load("Data/CMC_upwell_base.RData")
load("Data/SACTN_upwell_base.RData")
load("Data/MUR_upwell_base.RData")
load("Data/G1SST_upwell_base.RData")

# Removing the distance of 20 and 40kms
library(dplyr)
removing_distance_func <- function(df){
  removing_dist_func<- df %>% 
       filter(!distance %in% c(20000,40000))
}

OISST_final <- removing_distance_func(df = OISST_upwell_base)
G1SST_final <- removing_distance_func(df = G1SST_upwell_base)
MUR_final <- removing_distance_func(df = MUR_upwell_base)
CMC_final <- removing_distance_func(df = CMC_upwell_base)

# save(OISST_final, file = "Data/OISST_final.RData")
# save(G1SST_final, file = "Data/G1SST_final.RData")
# save(MUR_final, file = "Data/MUR_final.RData")
# save(CMC_final, file = "Data/CMC_final.RData")
```

To accurately compare 
  Start date CMC start date 1991-09-02 end date 2017-03-15
  Start date OISST start date 1981-09- 01  and end date 2018-09-28
  Start date SACTN start date 1973 and end date 2017-12-16
  
```{r}
#glm to determine if there is a difference in the number of events recorded at different at every distance

load("Data/Count/OISST_count.RData")
load("Data/Count/G1SST_count.RData")
load("Data/Count/MUR_count.RData")
load("Data/Count/CMC_count.RData")


options(scipen = 999)
anova_func <- function(df){
  sites_aov <- aov(distance ~ duration * site * site, data = df)
return(sites_aov)
}

OISST_anov <- anova_func(df = OISST_upwell_base)
summary(OISST_anov)
CMC_anov <- anova_func(df = CMC_upwell_base)
summary(CMC_anov)

MUR_anov <- anova_func(df = MUR_upwell_base)
summary(MUR_anov)

SACTN_anov <- aov(intensity_mean ~ site * duration, data = SACTN_upwell_base)
summary(SACTN_anov)




lm_coeff <- function(df){
  res <- lm(formula = val ~ date_peak, data = df)
  res_coeff <- round(as.numeric(res$coefficient[2]), 4)
}
# Changes in upwelling metrics
lm_func <- function(df){
  upwell_lm <- df %>% 
  select(-c(index_start:index_end)) %>% 
  gather(key = "var", value = "val", -c(site:date_end)) %>% 
  group_by(site, var, distance) %>% 
  nest() %>% 
  mutate(slope = purrr::map(data, lm_coeff)) %>% 
  select(-data) %>% 
  unnest() %>% 
  # convert from daily to decadal values
  mutate(slope = slope * 365.25*10)
}

OISST_lm <- lm_func(df = OISST_upwell_base)
CMC_lm <- lm_func(df = CMC_upwell_base)

SACTN_lm <- SACTN_upwell_base %>% 
  select(-c(index_start:index_end)) %>% 
  gather(key = "var", value = "val", -c(site:date_end)) %>% 
  group_by(site, var) %>% 
  nest() %>% 
  mutate(slope = purrr::map(data, lm_coeff)) %>% 
  select(-data) %>% 
  unnest() %>% 
  # convert from daily to decadal values
  mutate(slope = slope * 365.25*10)
```
  

As a common date we will use a start date from 1992-01-31 and end date 16-12-31

```{r}
# Generalosed linear models

# Generalized Linear Models- Look at the difference in metrics of in situ upwelling and remotely sensed SST data upwelling 
# Generalized linear models are fit using the glm( ) function. The form of the glm function is glm(formula, family=familytype(link=linkfunction), data=)

# trends_duration_func <- function(df){
#   upwellmodel <- glm(SACTN_upwell_base$duration[SACTN_upwell_base$event_no] ~ seq(1:length(SACTN_upwell_base$duration[SACTN_upwell_base$event_no])), 
#                      family = poisson(link = "log"))
#   upwellmodel0 <- glm(SACTN_upwell_base$duration[SACTN_upwell_base$event_no] ~ 1, family = poisson(link = "log")) # intercept only
#   dat2 <- data.frame(site = SACTN_upwell_base$site, upwelltrend = round(as.numeric(coef(upwellmodel)[2]*10),1),
#                        upwellR2 = round(1-logLik(upwellmodel)/logLik(upwellmodel0),2), # McFadden's pseudo-R2
#                        upwell.val = round(coef(summary(upwellmodel))[,4][2],2))
# }
# 
# OISST_trends_duration_func <- trends_duration_func(df = OISST_upwell_base)
# CMC_trends_duration_func <- trends_duration_func(df = CMC_upwell_base)
# SACTN_trends_duration_func <- trends_duration_func(df = SACTN_upwell_base)
# 
# 
# ### Intensity: Chnaged the family and link because of the negative values within the dataset 
# trends_intensity_func <- function(df){
#   upwellmodel <- glm(SACTN_upwell_base$intensity_mean[SACTN_upwell_base$event_no] ~ seq(1:length(SACTN_upwell_base$intensity_mean[SACTN_upwell_base$event_no])), 
#                      family = gaussian(link = "identity"))
#   upwellmodel0 <- glm(SACTN_upwell_base$intensity_mean[SACTN_upwell_base$event_no] ~ 1, family = gaussian(link = "identity")) # intercept only
#   dat2 <- data.frame(site = SACTN_upwell_base$site, upwelltrend = round(as.numeric(coef(upwellmodel)[2]*10),1),
#                        upwellR2 = round(1-logLik(upwellmodel)/logLik(upwellmodel0),2), # McFadden's psesudo-R2
#                        upwell.val = round(coef(summary(upwellmodel))[,4][2],2))
# }
# 
# OISST_trends_intensity_func <- trends_intensity_func(df = OISST_upwell_base)
# CMC_trends_intensity_func <- trends_intensity_func(df = CMC_upwell_base)
# SACTN_trends_intensity_func <- trends_intensity_func(df = SACTN_upwell_base)
```

# From the years 1992 - 2017

```{r}
# Which pixels showed the highest upwelling counts within the different datasets
# Which site showed the most intense upwelling within the different datasets

metric_func <- function(df){
 metrics <-df %>% 
  filter(year(date_start) %in% 1992:2017) %>% 
  #mutate(year = year(date_start)) %>% 
  group_by(distance, site) %>% 
  summarise(mean_intensity = mean(intensity_mean),
            sum_events = sum(event_no)) %>% 
   select(site, distance, mean_intensity, sum_events)
}

OISST_metrics <- metric_func(OISST_upwell_base)
CMC_metrics <- metric_func(CMC_upwell_base)

# No of u pwelling events found at the different sites
SACTN_metrics <- SACTN_upwell_base %>% 
  filter(year(date_start) %in% 1992:2017) %>% 
  group_by(site) %>% 
  summarise(mean_intensity = mean(intensity_mean),
            sum_events = sum(event_no)) %>% 
  select(site, mean_intensity, sum_events)

# Create a table showing these metrics


```

# Wind plots

```{r, fig.cap = "Windrose diagram representing the wind direction and speed for each of the sites", fig.height = 10, fig.width = 15}
library(ggradar)
library(dplyr)
library(scales)
library(tibble)
load("Data/UI_angle.RData")

# Detects NA values, no NA values are present
# Plotting wind variables
source("Functions/wind.rose.R") # This it may be related to the countmax = NA in the function

wind_daily_renamed <- UI_angle %>% 
  mutate(dir_circ = ifelse(dir_circ < 0, dir_circ+360, dir_circ)) %>% 
  dplyr::rename(spd = mean_speed) %>%
  dplyr::rename(dir = dir_circ) %>% 
  filter(spd > 0)

p.wr2 <- plot.windrose(data = wind_daily_renamed,
              spd = "spd",
              dir = "dir")

p.wr3 <- p.wr2 + facet_wrap(.~ site, ncol = 2, nrow = 2) +
  theme(strip.text.x = element_text(size = 25)) + theme(panel.spacing = unit(2, "lines"))
p.wr3

################3

# load("Data/UI_angle.RData")
# 
# wind_plot_prep <- UI_angle %>% 
#   select(-t, -ui.saws)
# 
# wind_plot <- wind_plot_prep %>% 
#   as_tibble(rownames = "site") %>% 
#   group_by(site) %>% 
#   mutate_at(vars(-site), rescale) %>% 
#   tail(4) 
# 
# ggradar(wind_plot)
# 
# ??countmax

```

# ANOVA
- Relationship between duration, year and site as a function of the distance 
The number of events per distance and then compare this at each distance 

```{r}
options(scipen = 999)
anova_func <- function(df){
  sites_aov <- aov(distance ~ duration * site * site, data = df)
return(sites_aov)
}

OISST_anov <- anova_func(df = OISST_upwell_base)
summary(OISST_anov)
CMC_anov <- anova_func(df = CMC_upwell_base)
summary(CMC_anov)

MUR_anov <- anova_func(df = MUR_upwell_base)
summary(MUR_anov)

SACTN_anov <- aov(intensity_mean ~ site * duration, data = SACTN_upwell_base)
summary(SACTN_anov)
```


Plot showing upwelling at the different sites for each of the different distances. Scatter plot

```{r}

load("Data/OISST_upwell_base.RData")
load("Data/CMC_upwell_base.RData")
load("Data/SACTN_upwell_base.RData")
load("Data/MUR_upwell_base.RData")
load("Data/G1SST_upwell_base.RData")

km_func <- function(df){
  upwell_base <-  df%>% 
      mutate(distance_km = case_when(distance == "10000" ~ "10",
                                    distance == "20000" ~ "20",
                                    distance  == "30000" ~"30",
                                    distance  == "40000" ~ "40",
                                    distance  == "50000" ~ "50"))
}
OISST_upwell_base <- km_func(df = OISST_upwell_base)
OISST_upwell_base$distance_km <- as.numeric(OISST_upwell_base$distance_km)

CMC_upwell_base <- km_func(df = CMC_upwell_base)
CMC_upwell_base$distance_km <- as.numeric(CMC_upwell_base$distance_km)

MUR_upwell_base <- km_func(df = MUR_upwell_base)
MUR_upwell_base$distance_km <- as.numeric(MUR_upwell_base$distance_km)

G1SST_upwell_base <- km_func(df = G1SST_upwell_base)
G1SST_upwell_base$distance_km <- as.numeric(G1SST_upwell_base$distance_km)

library(ggpubr)
year_func <- function(df){
  Filtered <- df %>%
filter(year(date_start) %in% seq(2011, 2013, 1))
}

CMC_filtered <- year_func(df = CMC_upwell_base)
OISST_filtered <- year_func(df = OISST_upwell_base)
SACTN_filtered <- year_func(df = SACTN_upwell_base)
MUR_filtered <- year_func(df = MUR_upwell_base)
G1SST_filtered <- year_func(df = G1SST_upwell_base)

CMC_SEAPOINT <- CMC_filtered %>% 
  filter(site == "Sea Point")
CMC_SB <- CMC_filtered %>% 
  filter(site == "Saldanha Bay")
CMC_PN <- CMC_filtered %>% 
  filter(site == "Port Nolloth")
CMC_LB <- CMC_filtered %>% 
  filter(site == "Lamberts Bay")

###################
## OISST
OISST_SEAPOINT <- OISST_filtered %>% 
  filter(site == "Sea Point")
OISST_SB <- OISST_filtered %>% 
  filter(site == "Saldanha Bay")
OISST_PN <- OISST_filtered %>% 
  filter(site == "Port Nolloth")
OISST_LB <- OISST_filtered %>% 
  filter(site == "Lamberts Bay")

############
#####MUR

MUR_SEAPOINT <- MUR_filtered %>% 
  filter(site == "Sea Point")
MUR_SB <- MUR_filtered %>% 
  filter(site == "Saldanha Bay")
MUR_PN <- MUR_filtered %>% 
  filter(site == "Port Nolloth")
MUR_LB <- MUR_filtered %>% 
  filter(site == "Lamberts Bay")
###########
####G1SST

G1SST_SEAPOINT <- G1SST_filtered %>% 
  filter(site == "Sea Point")
G1SST_SB <- G1SST_filtered %>% 
  filter(site == "Saldanha Bay")
G1SST_PN <- G1SST_filtered %>% 
  filter(site == "Port Nolloth")
G1SST_LB <- G1SST_filtered %>% 
  filter(site == "Lamberts Bay")

```

# Lolli plot

```{r}
plot_loli_func <- function(df){
  ggplot(df, aes(x = date_peak, y = duration)) + 
  geom_lolli(colour = "steelblue3", colour_n = "navy", n = 3) + 
  #scale_color_distiller(palette = "Spectral", name = "Cumulative \nintensity") + 
  facet_wrap(~distance_km, ncol = 2) +
  scale_y_continuous(breaks = c(5,10,15,20,25,30),
                     limits = c(1,30)) +
    scale_x_date(limits = as.Date(c("2011-01-01","2014-01-01"))) +
  theme_bw() +
  theme(axis.text=element_text(size=15),
        axis.title=element_text(size=17)) +
  theme(strip.text.x = element_text(size = 17))+
  theme(panel.spacing = unit(1, "lines")) +
    #theme(strip.text = c("10km", "20km", "30km", "40km", "50km")) +
  #strip=strip.custom(var.name=c("10km", "20km", "30km", "40km", "50km")) +
  xlab("Date (years)") + ylab("Event duration (days)") 
}


(OISST_SP_pl <- plot_loli_func(df = OISST_SEAPOINT))
(OISST_SB_pl <- plot_loli_func(df = OISST_SB))
(OISST_PN_pl <- plot_loli_func(df = OISST_PN))
(OISST_LB_pl <- plot_loli_func(df = OISST_LB))

OISST_SP_pl <- OISST_SP_pl +
  ggtitle("D.") #Sea Point
OISST_SB_pl <- OISST_SB_pl +
  ggtitle("C.") # Saldanha Bay
OISST_PN_pl <- OISST_PN_pl +
  ggtitle("B.")        # Port Nolloth
OISST_LB_pl <- OISST_LB_pl +
  ggtitle("A.")#Lamberts Bay

combined_OISST_pl_2 <- ggarrange(OISST_SB_pl, OISST_SP_pl) 

combined_OISST_pl_1 <- ggarrange(OISST_LB_pl, OISST_PN_pl)

#######
# CMC

(CMC_SP_pl <- plot_loli_func(df = CMC_SEAPOINT))
(CMC_SB_pl <- plot_loli_func(df = CMC_SB))
(CMC_PN_pl <- plot_loli_func(df = CMC_PN))
(CMC_LB_pl <- plot_loli_func(df = CMC_LB))

CMC_SP_pl <- CMC_SP_pl +
  ggtitle("D.") #Sea Point
CMC_SB_pl <- CMC_SB_pl +
  ggtitle("C.") # Saldanha Bay
CMC_PN_pl <- CMC_PN_pl +
  ggtitle("B.")        # Port Nolloth
CMC_LB_pl <- CMC_LB_pl +
  ggtitle("A.")#Lamberts Bay

combined_CMC_pl_2 <- ggarrange(CMC_SB_pl, CMC_SP_pl) 

combined_CMC_pl_1 <- ggarrange(CMC_LB_pl, CMC_PN_pl)

##########
### MUR
(MUR_SP_pl <- plot_loli_func(df = MUR_SEAPOINT))
(MUR_SB_pl <- plot_loli_func(df = MUR_SB))
(MUR_PN_pl <- plot_loli_func(df = MUR_PN))
(MUR_LB_pl <- plot_loli_func(df = MUR_LB))


MUR_SP_pl <- MUR_SP_pl +
  ggtitle("D.") #Sea Point
MUR_SB_pl <- MUR_SB_pl +
  ggtitle("C.") # Saldanha Bay
MUR_PN_pl <- MUR_PN_pl +
  ggtitle("B.")        # Port Nolloth
MUR_LB_pl <- MUR_LB_pl +
  ggtitle("A.")#Lamberts Bay


combined_MUR_pl_2 <- ggarrange(MUR_SB_pl, MUR_SP_pl) 

combined_MUR_pl_1 <- ggarrange(MUR_LB_pl, MUR_PN_pl)
#######
#G1SST

(G1SST_SP_pl <- plot_loli_func(df = G1SST_SEAPOINT))
(G1SST_SB_pl <- plot_loli_func(df = G1SST_SB))
(G1SST_PN_pl <- plot_loli_func(df = G1SST_PN))
(G1SST_LB_pl <- plot_loli_func(df = G1SST_LB))

G1SST_SP_pl <- G1SST_SP_pl +
  ggtitle("D.") #Sea Point
G1SST_SB_pl <- G1SST_SB_pl +
  ggtitle("C.") # Saldanha Bay
G1SST_PN_pl <- G1SST_PN_pl +
  ggtitle("B.")        # Port Nolloth
G1SST_LB_pl <- G1SST_LB_pl +
  ggtitle("A.")#Lamberts Bay

combined_G1SST_pl_2 <- ggarrange(G1SST_SB_pl, G1SST_SP_pl) 

combined_G1SST_pl_1 <- ggarrange(G1SST_LB_pl, G1SST_PN_pl)

########

plot_loli_func <- function(df){
  ggplot(df, aes(x = date_peak, y = duration)) + 
  geom_lolli(colour = "steelblue3", colour_n = "navy", n = 3) + 
  #scale_color_distiller(palette = "Spectral", name = "Cumulative \nintensity") + 
   facet_wrap(~site, ncol = 2) +
  scale_y_continuous(breaks = c(5,10,15,20,25,30),
                     limits = c(1,30)) +
  theme_bw() +
  theme(axis.text=element_text(size=17),
        axis.title=element_text(size=17)) +
  theme(strip.text.x = element_text(size = 17))+
  theme(panel.spacing = unit(0.5, "lines")) +
  #strip=strip.custom(var.name=c("10km", "20km", "30km", "40km", "50km")) +
  xlab("Date (years)") + ylab("Event duration (days)") 
}

(SACTN_plot <- plot_loli_func(df = SACTN_filtered))
```

# GLM - Determining if a change occur in the number of signals detected at different distances from the coastline
# Included a table in the paper
  Table discuss/count the number of upwelling signals detected at the different distances
  
  - For some of the sites it is seen that fewer upwelling signals are visible at a further distance from the coastline
  - When adding up all the signals observed at their respective distance it is seen that there are only slight differences in the amount of signals detected In some cases the signals detected at 10km from the coastline exceed that detected at 50km and visa versa

## Number of events detected

Using the start date and getting the month and year into a column. The month and year will be on the xaxis
Then count the number of times per month at different years signals are detected

```{r}
load("Data/OISST_final.RData")
load("Data/CMC_final.RData")
load("Data/SACTN_upwell_base.RData")
load("Data/MUR_final.RData")
load("Data/G1SST_final.RData")

month_year_func <- function(df){
  month_year_func<- df %>% 
    mutate(month = month(date_start, abbr = T, label = T)) %>% 
    separate(date_start, into = c("year", "month_no")) %>% 
    unite(month_year, month,year)
    # Now need to get the year into a seperate column from the start date. So now date_start is split in the dataset
}

OISST_prep <- month_year_func(df = OISST_final)
CMC_prep <- month_year_func(df = CMC_final)
G1SST_prep <- month_year_func(df = G1SST_final)
MUR_prep <- month_year_func(df = MUR_final)

# Combined dataset
# Combined_frequency <- read_excel("Data/Combined_frequency.xlsx")
# save(Combined_frequency, file = "Data/Combined_frequency.RData")
```

# Plotting

```{r}
load("Data/Combined_frequency.RData")

Combined_frequency <- Combined_frequency %>%
  mutate(t = parse_date(date, format = "%b_%Y"),
         distance = factor(distance))

ggplot(data = Combined_frequency, aes(x = distance, y = number_of_signals)) +
  geom_boxplot(aes(colour = product)) +
  theme(axis.text.x = element_text(angle = 90, hjust =1, vjust = 0.5))+
  #geom_smooth(aes(colour = product), method = "lm") +
  #labs(x = NULL) +
  facet_wrap(~site) 


ggplot(data = Combined_frequency, aes(x = t, y = number_of_signals, colour = product)) +
geom_point(aes(size = distance)) +
geom_smooth(method = "lm", size = 1.2)+
theme(axis.text.x = element_text(angle = 90, hjust =1, vjust = 0.5))

# Does not accurately show the months
# Plot need to include month_year, number of signals, distance and product ()

ggplot(data = Combined_frequency, aes(x = t, y = number_of_signals)) +
  geom_line(aes(colour = product)) +
  geom_smooth(aes(colour = product), method = "lm") +
  labs(x = NULL) +
  facet_wrap(~site) #+
  # theme(axis.text.x = element_text(angle = 90, hjust =1, vjust = 0.5))


ggplot(data = Combined_frequency, aes(x = t, y = number_of_signals)) +
  geom_line(aes(colour = distance)) +
  geom_point(aes(colour = distance)) +
  geom_smooth(aes(colour = distance), method = "lm") +
  # labs(x = NULL) +
  facet_wrap(~site) #+
  theme(axis.text.x = element_text(angle = 90, hjust =1, vjust = 0.5))
  
  ggplot(data = Combined_frequency, aes(x = date, y = number_of_signals)) +
  geom_line(aes(colour = distance)) +
  geom_point(aes(colour = distance)) +
  geom_smooth(aes(colour = distance), method = "lm") +
  # labs(x = NULL) +
  facet_wrap(~site) #+
  theme(axis.text.x = element_text(angle = 90, hjust =1, vjust = 0.5))

####

combined_frequency_split <- Combined_frequency %>% 
  separate(date, into = c("month", "year"))

# ggplot(data = combined_frequency_split, aes(x = year, y = number_of_signals)) +
#   geom_line(aes(colour = month)) +
#   geom_smooth(aes(colour = month), method = "lm") +
#   facet_wrap(~site)
```

#Pairwise correlations
Comparing the relaionship of variables within the same sample

  -Correlate the 1st pixel with the second pixel and the first pixel with the last pixel
  -Correlation between satellite data and number of signals at the different distances from the coastline
  
```{r}

# chi squared test

load("Data/Combined_frequency.RData")

combined_freq_spread <- pivot_wider(Combined_frequency, names_prefix = "dist_",
                                    names_from = distance, values_from = number_of_signals)

save(combined_freq_spread, )

slope_calc <- function(df){
  df %>% 
    # mutate(row_num = 1:n()) %>% 
    # do(mod1 = lm(number_of_signals ~ row_num, data = .),
       # mod2 = lm(distance ~ row_num, data = .),
       # mod3 = lm(distance ~ number_of_signals, data = .),
       # mod4 = cor(.$distance, .$number_of_signals, method = "pearson", use = "complete.obs")[1]) %>% 
        # mutate(distance_slope = summary(mod1)$coeff[2],
        #    signal_slope = summary(mod2)$coeff[2],
        #    signal_distance_slope = summary(mod3)$coeff[2],
        #    signal_distance_r = mod4[1],
        #    signal_distance_r2 = glance(mod3)$adj.r.squared) %>%
        # select(-mod1, -mod2, -mod3, -mod4) %>% 
    do(mod1 = cor(.$dist_10, .$dist_30, method = "pearson", use = "complete.obs"),
       mod2 = cor(.$dist_10, .$dist_50, method = "pearson", use = "complete.obs")) %>%
    mutate(dist_10_vs_30_r = mod1[1],
           dist_10_vs_50_r = mod2[1]) %>% 
    # select(dist_10_vs_30_r, dist_10_vs_50_r) %>% 
    select(-mod1, -mod2) %>% 
    mutate_if(is.numeric, round, 2)
}

# test <- cor(combined_freq_spread$`10`, combined_freq_spread$`30`)

distance_corr <- combined_freq_spread %>% 
  group_by(site, product) %>% 
  slope_calc()




```


```{r}
library(hrbrthemes)
library(viridis)

Combined_frequency <- Combined_frequency %>%
  mutate(t = parse_date(date, format = "%b_%Y"),
         distance = factor(distance))
 

ggplot(Combined_frequency, aes(x=t, y=number_of_signals, size=distance, color=product)) +
  geom_point(alpha=0.5) +
  facet_wrap(~site) +
  theme(axis.text.x = element_text(angle = 90, hjust =1, vjust = 0.5))

ggplot(Combined_frequency, aes(x=date, y=number_of_signals, size=distance, color=product)) +
  geom_point(alpha=0.5) +
  facet_wrap(~site) +
  theme(axis.text.x = element_text(angle = 90, hjust =1, vjust = 0.5))

### Without time

ggplot(Combined_frequency, aes(x=distance, y= number_of_signals, color=product)) +
  geom_point(alpha=0.5) +
  facet_wrap(~site) +
  theme(axis.text.x = element_text(angle = 90, hjust =1, vjust = 0.5))

```

# Histogram

```{r}


combined_frequency_season <- Combined_frequency %>% 
  mutate(month = month(date, abbr = T, label = T),
         year = year(date)) %>% 
  mutate(season = ifelse(month %in% c("Jan", "Feb", "Mar"), "Summer",        
                           ifelse(month %in% c("Apr", "May", "Jun"), "Autumn",
                                ifelse(month %in% c("Jul", "Aug", "Sep"), "Winter",
                                       ifelse(month %in% c("Oct", "Nov", "Dec"), "Spring","Error")))))


CMC_dur <- read_excel("Data/CMC_dur.xlsx")

ggplot(data = CMC_dur, aes(x = duration)) +
  geom_histogram(aes(fill = product),  
                       position = "dodge", alpha=0.6) +
   labs(x = "Duration (Days)", y = "Number of upwelling signals", colour = "Temperature products") +
  facet_wrap(~site) +
theme_bw() 



ggplot(CMC_dur, aes(duration, colour = product)) +
  geom_freqpoly() +
  facet_wrap(~ site)
             
month_year_func <- function(df){
  month_year_func<- df %>% 
    mutate(month = month(date_start, abbr = T, label = T)) %>% 
    separate(date_start, into = c("year", "month_no")) %>% 
    unite(month_year, month,year)
    # Now need to get the year into a seperate column from the start date. So now date_start is split in the dataset
}

OISST_prep <- month_year_func(df = OISST_final)
CMC_prep <- month_year_func(df = CMC_final)
G1SST_prep <- month_year_func(df = G1SST_final)
MUR_prep <- month_year_func(df = MUR_final)

# Combined dataset
# Combined_frequency <- read_excel("Data/Combined_frequency.xlsx")
# save(Combined_frequency, file = "Data/Combined_frequency.RData")
```

# Plotting

```{r}
load("Data/Combined_frequency.RData")

Combined_frequency <- Combined_frequency %>%
  mutate(t = parse_date(date, format = "%b_%Y"),
         distance = factor(distance))

ggplot(data = Combined_frequency, aes(x = distance, y = number_of_signals)) +
  geom_boxplot(aes(colour = product)) +
  theme(axis.text.x = element_text(angle = 90, hjust =1, vjust = 0.5))+
  #geom_smooth(aes(colour = product), method = "lm") +
  #labs(x = NULL) +
  facet_wrap(~site) 


ggplot(data = Combined_frequency, aes(x = t, y = number_of_signals, colour = product)) +
geom_point(aes(size = distance)) +
geom_smooth(method = "lm", size = 1.2)+
theme(axis.text.x = element_text(angle = 90, hjust =1, vjust = 0.5))

# Does not accurately show the months
# Plot need to include month_year, number of signals, distance and product ()

ggplot(data = Combined_frequency, aes(x = t, y = number_of_signals)) +
  geom_line(aes(colour = product)) +
  geom_smooth(aes(colour = product), method = "lm") +
  labs(x = NULL) +
  facet_wrap(~site) #+
  # theme(axis.text.x = element_text(angle = 90, hjust =1, vjust = 0.5))


ggplot(data = Combined_frequency, aes(x = t, y = number_of_signals)) +
  geom_line(aes(colour = distance)) +
  geom_point(aes(colour = distance)) +
  geom_smooth(aes(colour = distance), method = "lm") +
  # labs(x = NULL) +
  facet_wrap(~site) #+
  theme(axis.text.x = element_text(angle = 90, hjust =1, vjust = 0.5))
  
  ggplot(data = Combined_frequency, aes(x = date, y = number_of_signals)) +
  geom_line(aes(colour = distance)) +
  geom_point(aes(colour = distance)) +
  geom_smooth(aes(colour = distance), method = "lm") +
  # labs(x = NULL) +
  facet_wrap(~site) #+
  theme(axis.text.x = element_text(angle = 90, hjust =1, vjust = 0.5))

####

combined_frequency_split <- Combined_frequency %>% 
  separate(date, into = c("month", "year"))

# ggplot(data = combined_frequency_split, aes(x = year, y = number_of_signals)) +
#   geom_line(aes(colour = month)) +
#   geom_smooth(aes(colour = month), method = "lm") +
#   facet_wrap(~site)
```

#Pairwise correlations
Comparing the relaionship of variables within the same sample

  -Correlate the 1st pixel with the second pixel and the first pixel with the last pixel
  -Correlation between satellite data and number of signals at the different distances from the coastline
  
```{r}

# chi squared test

load("Data/Combined_frequency.RData")

combined_freq_spread <- pivot_wider(Combined_frequency, names_prefix = "dist_",
                                    names_from = distance, values_from = number_of_signals)

slope_calc <- function(df){
  df %>% 
    # mutate(row_num = 1:n()) %>% 
    # do(mod1 = lm(number_of_signals ~ row_num, data = .),
       # mod2 = lm(distance ~ row_num, data = .),
       # mod3 = lm(distance ~ number_of_signals, data = .),
       # mod4 = cor(.$distance, .$number_of_signals, method = "pearson", use = "complete.obs")[1]) %>% 
        # mutate(distance_slope = summary(mod1)$coeff[2],
        #    signal_slope = summary(mod2)$coeff[2],
        #    signal_distance_slope = summary(mod3)$coeff[2],
        #    signal_distance_r = mod4[1],
        #    signal_distance_r2 = glance(mod3)$adj.r.squared) %>%
        # select(-mod1, -mod2, -mod3, -mod4) %>% 
    do(mod1 = cor(.$dist_10, .$dist_30, method = "pearson", use = "complete.obs"),
       mod2 = cor(.$dist_10, .$dist_50, method = "pearson", use = "complete.obs")) %>%
    mutate(dist_10_vs_30_r = mod1[1],
           dist_10_vs_50_r = mod2[1]) %>% 
    # select(dist_10_vs_30_r, dist_10_vs_50_r) %>% 
    select(-mod1, -mod2) %>% 
    mutate_if(is.numeric, round, 2)
}

#### test <- cor(combined_freq_spread$`10`, combined_freq_spread$`30`)

distance_corr <- combined_freq_spread %>% 
  group_by(site, product) %>% 
  slope_calc()


```


```{r}
library(hrbrthemes)
library(viridis)

Combined_frequency <- Combined_frequency %>%
  mutate(t = parse_date(date, format = "%b_%Y"),
         distance = factor(distance))
 

ggplot(Combined_frequency, aes(x=t, y=number_of_signals, size=distance, color=product)) +
  geom_point(alpha=0.5) +
  facet_wrap(~site) +
  theme(axis.text.x = element_text(angle = 90, hjust =1, vjust = 0.5))

ggplot(Combined_frequency, aes(x=date, y=number_of_signals, size=distance, color=product)) +
  geom_point(alpha=0.5) +
  facet_wrap(~site) +
  theme(axis.text.x = element_text(angle = 90, hjust =1, vjust = 0.5))

### Without time

ggplot(Combined_frequency, aes(x=distance, y= number_of_signals, color=product)) +
  geom_point(alpha=0.5) +
  facet_wrap(~site) +
  theme(axis.text.x = element_text(angle = 90, hjust =1, vjust = 0.5))

```

# Histogram

```{r}


combined_frequency_season <- Combined_frequency %>% 
  mutate(month = month(date, abbr = T, label = T),
         year = year(date)) %>% 
  mutate(season = ifelse(month %in% c("Jan", "Feb", "Mar"), "Summer",        
                           ifelse(month %in% c("Apr", "May", "Jun"), "Autumn",
                                ifelse(month %in% c("Jul", "Aug", "Sep"), "Winter",
                                       ifelse(month %in% c("Oct", "Nov", "Dec"), "Spring","Error")))))


CMC_dur <- read_csv("Data/CMC_dur.csv")

ggplot(data = CMC_dur, aes(x = duration)) +
  geom_histogram(aes(fill = product),  
                       position = "dodge", alpha=0.6) +
   labs(x = "Duration (Days)", y = "Number of upwelling signals", colour = "Temperature products") +
  facet_wrap(~site) +
  scale_colour_Publication()+
  theme_Publication()




ggplot(CMC_dur, aes(duration, colour = product)) +
  geom_freqpoly() +
  facet_wrap(~site) +
  theme_bw()
```

### Looking at intensity

```{r}

filt_func <- function(df){
  intens <- df %>% 
  #mutate(year = year(date_start)) %>% 
  filter(year(date_start) %in% seq(2011, 2012))
}

filt_func2 <- function(df){
  intens1 <- df %>% 
  #mutate(year = year(date_start)) %>% 
  filter(year(date_start) %in% seq(2013, 2014))
}

OISST_filt_func <- filt_func(OISST_final)
OISST_filt_func2 <- filt_func2(OISST_final)
OISST_binding <- rbind(OISST_filt_func,OISST_filt_func2)# %>% 
 # select(site, product, intensity_mean)


MUR_filt_func <- filt_func(MUR_final)
MUR_filt_func2 <- filt_func2(MUR_final)
MUR_binding <- rbind(MUR_filt_func,MUR_filt_func2)# %>% 
 # select(site, product, intensity_mean)

G1SST_filt_func <- filt_func(G1SST_final)
G1SST_filt_func2 <- filt_func2(G1SST_final)
G1SST_binding <- rbind(G1SST_filt_func,G1SST_filt_func2) #%>% 
  #select(site, product, intensity_mean)


CMC_filt_func <- filt_func(CMC_final)
CMC_filt_func2 <- filt_func2(CMC_final)
CMC_binding <- rbind(CMC_filt_func,CMC_filt_func2) #%>% 
 # select(site, product, intensity_mean)

SACTN_upwell_base_ <- read_csv("Data/SACTN_upwell_base .csv") # The SACTN product column was added in 

SACTN_filt_func <- filt_func(SACTN_upwell_base_)
SACTN_filt_func2 <- filt_func2(SACTN_upwell_base_)
SACTN_binding <- rbind(SACTN_filt_func,SACTN_filt_func2)# %>% 
# write.csv(SACTN_binding,'SACTNfinal_data.csv')

Complete_mean_intensity <- rbind(CMC_binding,OISST_binding, G1SST_binding, MUR_binding) %>% 
  ungroup() %>% 
  select(-heading, - distance, -distance_km) # Here I remove distance, Keep if distance is needed

#write.csv(Complete_mean_intensity ,'Complete_mean_intensity.csv') # Copied this and then removedsome columnss

final_data <- rbind(Complete_mean_intensity, SACTN_binding)
# write.csv(final_data,'final_data.csv')

```

# PLotting

```{r}

signals_average <- read_csv("Data/signals_average.csv")

ggplot(data = signals_average, aes(x = no_of_signals, y = intensity_mean)) +
  geom_point(aes(colour = product), size = 3) +
  geom_smooth(method = "lm") +
  facet_wrap(~site) + 
  labs(x = "Number of signals ", y = "Average intensity (°C)") +
  scale_colour_Publication()+
  theme_Publication()



ggplot(data =final_intensity, aes(x = intensity_mean)) +
  geom_histogram(aes(fill = product),  
                       position = "dodge", alpha=0.6) +
  # labs(x = "Duration (Days)", y = "Number of upwelling signals", colour = "Temperature products") +
  facet_wrap(~site) +
theme_bw() ---
title: "SST_patterns"
author: "Amieroh Abrahams"
date: "19 August 2019"
output: html_document

knitr::opts_chunk$set(
  comment = "R>",
  warning = FALSE,
  message = FALSE 
)
#update.packages() 
library(tidyverse)
library(lubridate)
library(ggpubr)
library(zoo)
library(FNN)
library(scales)
library(gridExtra)
library(circular)
library(fossil)
library(mapproj)
library(broom)
# library(ncdf4) # This was used to process NetCDF files in an earlier version
library(stringr)
library(doMC); doMC::registerDoMC(cores = 4)
library(fasttime)
library(xtable)
library(ncdf4) # library for processing netCDFs
library(data.table)
# library(plyr) # RWS: Never load the plyr package as it interferes with the tidyverse
library(heatwaveR)
library(grid)
library(ggthemes)
```

# Loading in all the data created using the code bellow

```{r}
load("Data/site_list_sub.Rdata")
load("Data/SACTN_US.RData")
load("Data/site_pixels.RData") # 5 decimal places
load("Data/OISST.RData") # 2 decimal places
OISST <- BC_avhrr_only_v2_Document_Document 
rm(BC_avhrr_only_v2_Document_Document ); gc()
load("Data/CMC.RData") # 1decimal places
```

# PLotting theme

```{r}
theme_Publication <- function(base_size=14, base_family="helvetica") {
      library(grid)
      library(ggthemes)
      (theme_foundation(base_size=base_size, base_family=base_family)
       + theme(plot.title = element_text(face = "bold",
                                         size = rel(1.2), hjust = 0.5),
               text = element_text(),
               panel.background = element_rect(colour = NA),
               plot.background = element_rect(colour = NA),
               panel.border = element_rect(colour = NA),
               axis.title = element_text(face = "bold",size = rel(1)),
               axis.title.y = element_text(angle=90,vjust =2),
               axis.title.x = element_text(vjust = -0.2),
               axis.text = element_text(), 
               axis.line = element_line(colour="black"),
               axis.ticks = element_line(),
               panel.grid.major = element_line(colour="#f0f0f0"),
               panel.grid.minor = element_blank(),
               legend.key = element_rect(colour = NA),
               legend.position = "bottom",
               legend.direction = "horizontal",
               legend.key.size= unit(0.2, "cm"),
               legend.margin = unit(0, "cm"),
               #legend.title = element_text(face="italic"),
               plot.margin=unit(c(10,5,5,5),"mm"),
               strip.background=element_rect(colour="#f0f0f0",fill="#f0f0f0"),
               strip.text = element_text(face="bold")
          ))
      
}

scale_fill_Publication <- function(...){
      library(scales)
      discrete_scale("fill","Publication",manual_pal(values = c("#386cb0","#fdb462","#7fc97f","#ef3b2c","#662506","#a6cee3","#fb9a99","#984ea3","#ffff33")), ...)

}

scale_colour_Publication <- function(...){
      library(scales)
      discrete_scale("colour","Publication",manual_pal(values = c("#386cb0","#fdb462","#7fc97f","#ef3b2c","#662506","#a6cee3","#fb9a99","#984ea3","#ffff33")), ...)

}
```


```{r}
# SACTN_US <- SACTN_US %>% 
#   dplyr::rename(in_situ_temp = temp)
# 
# # Visualising the data
# temp_plot <- function(df){
#   plot <- ggplot(data = df, aes(x = date, y = in_situ_temp, colour = site)) +
#     geom_line(aes(group = site)) +
#     labs(x = "", y = "Temperature (°C)") +
#     theme(axis.text.x = element_text(angle = 45)) +
#     theme(legend.position = "top")
# }
# 
# SACTN_plot <- temp_plot(df = SACTN_US)
# SACTN_plot


# 25th quantile
```

Different distances from the coastline

```{r}
# load("Data/site_list_sub.Rdata")
# # xtable(site_list_sub, auto = TRUE)
# west <- site_list_sub
# west$coast <- "west" # Chnages wc to west
# 
# load("Data/africa_coast.RData")
# 
# ## Downloading the bathy data from NOAA
# # Download mid-res bathymetry data
# # sa_lat <- c(-38, -24.5); sa_lon <- c(11.5, 35.5)
# # sa_bathy <- as.xyz(getNOAA.bathy(lon1 = sa_lon[1], lon2 = sa_lon[2], lat1 = sa_lat[1], lat2 = sa_lat[2], resolution = 4))
# # colnames(sa_bathy) <- c("lon", "lat", "depth")
# # sa_bathy <- sa_bathy[sa_bathy$depth <= 0,]
# # save(sa_bathy, file = "Data_P1/bathy/sa_bathy.RData")
# 
# # Loading in the newly downloaded bathymetry data               
# load("Data/bathy/sa_bathy.RData")

# # This function takes one site (e.g. one set of lon/lats) and calculates a shore normal transect
# shore.normal.transect <- function(site, width = 2){
#   # Find the site on the coastline and it's nearest neighbour points
#   coords <- data.frame(lon = site$lon, lat = site$lat)
#   coords2 <- knnx.index(africa_coast[,1:2], as.matrix(coords), k = 1)
#   coords3 <- data.frame(site = site$site, africa_coast[c(coords2-width, coords2+width),]) 
#   coords3 <- coords3[2:1,1:3]
#   # Define the shore normal transect bearing
#   heading <- earth.bear(coords3[1,2], coords3[1,3], coords3[2,2], coords3[2,3]) + 90
#   if(heading >= 360){
#     heading <- heading-360
#   } else {
#     heading <- heading
#   }
#   heading2 <- data.frame(site = site$site, lon = site$lon, lat = site$lat, heading)
#   return(heading2)
# }
# 
# # Creating the transects
# site_transects <- data.frame()
# for(i in 1:length(west$site)){
#  site <- west[i,]
#  site_transect <- shore.normal.transect(site, 2)
#  site_transects <- rbind(site_transects, site_transect)
# }
# 
# # Manually correcting Sea Point and Kommetjie
# site_transects$heading[4:5] <- 290 
# # save(site_transects, file = "Data/site_transects.RData")
# load("Data/site_transects.RData")
# 
# # This function takes one site (e.g. one set of lon/lats) and calculates a shore norm./subal transect
# # It then extracts a lat/ lon point every X kilometres until reaching a specified isobath
# 
# transect.pixel <- function(site, distances){
#   # Extract coordinates
#   coords <- data.frame(lon = site$lon, lat = site$lat)
#   # Find lon/ lats every X metres 
#   pixels <- data.frame()
#   # deep <- 999
#   # distance_multiplier <- 1
#   # while(deep > isobath){
#   for(i in 1:length(distances)){
#     coords2 <- as.data.frame(destPoint(p = coords, b = site$heading, d = distances[i]))
#     sitesIdx <- knnx.index(sa_bathy[,1:2], as.matrix(coords2), k = 1)
#     bathy2 <- sa_bathy[sitesIdx,]
#     bathy2 <- bathy2[complete.cases(bathy2$depth),]
#     bathy3 <- data.frame(site = site$site, lon = bathy2$lon, lat = bathy2$lat, 
#                          heading = site$heading, 
#                          distance = distances[i])
#     pixels <- rbind(pixels, bathy3)
#     coords <- coords2
#   }
#   if(nrow(pixels) < 1){
#     pixels <- data.frame(site, depth = NA)
#   }else{
#     pixels <- pixels
#   }+

#   return(pixels)
# }
# 
# # Pixel points
# site_pixels <- data.frame()
# for(i in 1:length(west$site)){
#   site <- site_transects[i,]
#   site_pixel <- transect.pixel(site, c(10000, 20000, 30000, 40000, 50000)) # RWS: fixed error
#   site_pixels <- rbind(site_pixels, site_pixel)
# }
# 
# # Bounding box
#   # Only one is made in order to know how large the the geom_point() squares should be made to match
# bbox <- data.frame(xmin = destPoint(p = site_pixels[1,2:3], b = 270, d = 12500)[1],
#                    xmax = destPoint(p = site_pixels[1,2:3], b = 90, d = 12500)[1],
#                    ymin = destPoint(p = site_pixels[1,2:3], b = 180, d = 12500)[2],
#                    ymax = destPoint(p = site_pixels[1,2:3], b = 0, d = 12500)[2])
# 
# # Determining the temperature at the various distances from the coast
# 
# # save(site_pixels, file = "Data/site_pixels.RData")
# load("Data/site_pixels.RData")


```

# Extrcting the MUR data

```{r}
# library(stringr)
# library(tidyverse)
# library(reshape2)
# library(ncdf4) # library for processing netCDFs
# library(plyr)
# library(lubridate)
# library(data.table)
# library(doMC); doMC::registerDoMC(cores = 7)
# 
# ncDir <- "/home/amieroh/Documents/Data/Datasets/MUR/daily"
# csvDir <- "/media/amieroh/Seagate Expansion Drive/Extracted G1SST/MUR_extracted"
# 
# #          1         2         3         4
# # 12345678901234567890123456789012345678901
# # 20020601-JPL-L4UHfnd-GLOB-v01-fv04-MUR.nc
# 
# read_nc <- function(ncDir = ncDir, csvDir = csvDir)
#   ncList <- list.files(path = paste0(ncDir), pattern = "*.nc", full.names = TRUE, include.dirs = TRUE)
#   ncFirst <- head(list.files(path = paste0(ncDir, "/"), pattern = "*.nc", full.names = FALSE), 1)
#   ncLast <- tail(list.files(path = paste0(ncDir, "/"), pattern = "*.nc", full.names = FALSE), 1)
#   strtDate <- str_sub(ncFirst, start = 1, end = 8)
#   endDate <- str_sub(ncLast, start = 1, end = 8)
# 
# # ncFile <- '/home/amieroh/Documents/Data/Datasets/MUR/daily/20020606-JPL-L4UHfnd-GLOB-v01-fv04-MUR.nc'
# 
#   ncFun <- function(ncFile = ncFile, csvDir = csvDir) {
#     nc <- nc_open(ncFile)
#     pathLen <- nchar(paste0(ncDir, "/")) + 1
# fNameStem <-
#   substr(basename(ncFile), 10, 38)
#     fDate <- substr(basename(ncFile), 1, 8)
#     sst <- ncvar_get(nc, varid = "analysed_sst") %>%
#       round(4)
#     dimnames(sst) <- list(lon = nc$dim$lon$vals,
#                           lat = nc$dim$lat$vals)
#     nc_close(nc)
#     sst <- as_tibble(melt(sst, value.name = "temp"))
#     sst$t <- ymd(fDate)
#     na.omit(sst)
#     fwrite(sst,
#            file = paste0(csvDir, "/", fNameStem, "-", strtDate, "-", endDate, ".csv"),
#            append = TRUE, col.names = FALSE)
#     rm(sst)
#   }
# 
# llply(ncList, ncFun, csvDir = csvDir, .parallel = TRUE)

# MUR <- read_csv("/home/amieroh/Documents/Data/Datasets/MUR/Extracted_MUR/BC-JPL-L4UHfnd-GLOB-v01-fv04-MUR-20020601-20140727.csv")
# names(MUR)<-c("lon","lat", "temp", "date")
# MUR <- MUR %>% 
#   mutate(temp = temp - 273.15)
# 
# JPL_L4UHfnd_GLOB_v01_fv04_MUR_20020601_20140727 <- read_csv("~/Documents/JPL-L4UHfnd-GLOB-v01-fv04-MUR-20020601-20140727.csv")
# 
# ######################################### SUBSET VIA REGION #################
# 
# # bbox <- data.frame(BC = c(-35, -25, 15, 20), # Benguela Current
# library(stringr)
# library(tidyverse)
# library(reshape2)
# library(ncdf4) # library for processing netCDFs
# library(plyr)
# library(lubridate)
# library(data.table)
# library(doMC); doMC::registerDoMC(cores = 7)
# ncDir <- "/home/amieroh/Documents/Data/Datasets/MUR/daily"
# csvDir <- "/home/amieroh/Documents/Data/Datasets/MUR/Extracted_MUR"
# #          1         2         3         4
# # 12345678901234567890123456789012345678901
# # 20020601-JPL-L4UHfnd-GLOB-v01-fv04-MUR.nc
# 
# # ncFile <- '/home/amieroh/Documents/Data/Datasets/MUR/daily/20020606-JPL-L4UHfnd-GLOB-v01-fv04-MUR.nc'
#   ncFun <- function(ncFile = ncFile, region = region, csvDir = csvDir) {
#     coords <- bbox[, region]
#     nc <- nc_open(ncFile)
#     pathLen <- nchar(paste0(ncDir, "/")) + 1
#     fNameStem <-
#       substr(basename(ncFile), 10, 38)
#     fDate <- substr(basename(ncFile), 1, 8)
#     LatIdx <- which(nc$dim$lat$vals > coords[1] & nc$dim$lat$vals < coords[2])
#     LonIdx <- which(nc$dim$lon$vals > coords[3] & nc$dim$lon$vals < coords[4])
#     sst <- ncvar_get(nc, varid = "analysed_sst") %>%
#       round(4)
#     dimnames(sst) <- list(lon = nc$dim$lon$vals,
#                           lat = nc$dim$lat$vals)
#     nc_close(nc)
#     sst <- as_tibble(melt(sst, value.name = "temp"))
#     sst$t <- ymd(fDate)
#     na.omit(sst)
#     fwrite(sst,
#            file = paste0(csvDir, "/", region, "-", fNameStem, "-", strtDate, "-", endDate, ".csv"),
#            append = TRUE, col.names = FALSE)
#     rm(sst)
#   }
#   
#   
#   ncList <- list.files(path = paste0(ncDir), pattern = "*.nc", full.names = TRUE, include.dirs = TRUE)
#   ncFirst <- head(list.files(path = paste0(ncDir, "/"), pattern = "*.nc", full.names = FALSE), 1)
#   ncLast <- tail(list.files(path = paste0(ncDir, "/"), pattern = "*.nc", full.names = FALSE), 1)
#   strtDate <- str_sub(ncFirst, start = 1, end = 8)
#   endDate <- str_sub(ncLast, start = 1, end = 8)  
#   
# llply(ncList, ncFun, region = "BC", csvDir = csvDir, .parallel = TRUE)
```

# Extracting the CMC data

```{r}
# ncDir <- "/home/amieroh/Documents/Data/Datasets/CMC/CMC_BC"
# csvDir <- "/home/amieroh/Documents/Data/Datasets/CMC/CMC_extracted"
# 
# #          1         2         3         4         5         6
# # 123456789012345678901234567890123456789012345678901234567890
# # 20100609-JPL_OUROCEAN-L4UHfnd-GLOB-v01-fv01_0-G1SST_subset.nc
# read_nc <- function(ncDir = ncDir, csvDir = csvDir) 
#   ncList <- list.files(path = paste0(ncDir), pattern = "*.nc", full.names = TRUE, include.dirs = TRUE)
#   ncFirst <- head(list.files(path = paste0(ncDir, "/"), pattern = "*.nc", full.names = FALSE), 1)
#   ncLast <- tail(list.files(path = paste0(ncDir, "/"), pattern = "*.nc", full.names = FALSE), 1)
#   strtDate <- str_sub(ncFirst, start = 1, end = 8)
#   endDate <- str_sub(ncLast, start = 1, end = 8)
# 
# # ncFile <- '/home/amieroh/Documents/Data/Datasets/CMC/CMC_BC/20100609-JPL_OUROCEAN-L4UHfnd-GLOB-v01-fv01_0-G1SST_subset.nc'
# 
#   ncFun <- function(ncFile = ncFile, csvDir = csvDir) {
#     nc <- nc_open(ncFile)
#     pathLen <- nchar(paste0(ncDir, "/")) + 1
#     fNameStem <-
#       substr(basename(ncFile), 10, 58)
#     fDate <- substr(basename(ncFile), 1, 8)
#     sst <- ncvar_get(nc, varid = "analysed_sst") %>%
#       round(4)
#     dimnames(sst) <- list(lon = nc$dim$lon$vals,
#                           lat = nc$dim$lat$vals)
#     nc_close(nc)
#     sst <- as_tibble(melt(sst, value.name = "temp"))
#     sst$t <- ymd(fDate)
#     na.omit(sst)
#     fwrite(sst,
#            file = paste0(csvDir, "/", fNameStem, "-", strtDate, "-", endDate, ".csv"),
#            append = TRUE, col.names = FALSE)
#     rm(sst)
#   }
# 
# llply(ncList, ncFun, csvDir = csvDir, .parallel = TRUE)
# 
# 
# CMC <- read_csv("/home/amieroh/Documents/Data/Datasets/CMC/CMC_extracted/Benguela_current/20000-CMC-L4_GHRSST-SSTfnd-CMC0.2deg-GLOB-v02.0-f-19910901-20170317.csv")
# names(CMC)<-c("lon","lat", "temp", "date")
# CMC <- CMC %>% 
#   mutate(temp = temp - 273.15)
# 
# # save(CMC, file = "Data/CMC.RData")
```

# Extracting the OISST data

```{r}
# bbox <- data.frame(BC = c(-35, -25, 15, 20), # Benguela Current
#                    CC = c(25, 35, 340, 355), # Canary Current
#                    CalC = c(35, 45, 225, 240), # California Current
#                    HC = c(-17.5, -7.5, 275, 290), # Humboldt Current
#                    row.names = c("latmin", "latmax", "lonmin", "lonmax"))
# 
# OISST.dir <- "/home/amieroh/Documents/Data/Datasets/OISSTv2/daily/netCDF/avhrr-only"
# OISST.csv.dir <- "/home/amieroh/Documents/Data/Datasets/OISST_subset"
# 
# #          1         2
# # 1234567890123456789012345
# # avhrr-only-v2.19810901.nc
# 
# # function to extract the dims and data from OISST netCDFs
# read_nc <- function(ncFile, region = region, csvDir = csvDir) {
#   coords <- bbox[, region]
#   nc <- nc_open(ncFile)
#   pathLen <- nchar(OISST.dir) + 1 # to account for the "/" that needs to be inserted
#   fNameStem <-
#     substr(ncFile, pathLen + 1, pathLen + 13)
#   fDate <- substr(ncFile, pathLen + 15, pathLen + 22)
#   LatIdx <- which(nc$dim$lat$vals > coords[1] & nc$dim$lat$vals < coords[2])
#   LonIdx <- which(nc$dim$lon$vals > coords[3] & nc$dim$lon$vals < coords[4])
#   sst <- ncvar_get(nc,
#                    varid = "sst",
#                    start = c(LonIdx[1], LatIdx[1], 1, 1),
#                    count = c(length(LonIdx), length(LatIdx), 1, 1)) %>%
#     round(4)
#   dimnames(sst) <- list(lon = nc$dim$lon$vals[LonIdx],
#                         lat = nc$dim$lat$vals[LatIdx])
#   nc_close(nc)
#   sst <-
#     as.data.table(melt(sst, value.name = "temp"), row.names = NULL) %>%
#     mutate(t = ymd(fDate)) %>%
#     na.omit()
#   fwrite(sst,
#          file = paste(csvDir, "/", region, "-", fNameStem, ".", strtDate, "-", endDate, ".csv", sep = ""),
#          append = TRUE, col.names = FALSE)
#   rm(sst)
# }
# 
# # the list of files
# ncList <- list.files(path = OISST.dir, pattern = "*.nc", full.names = TRUE, include.dirs = TRUE)
# strtDate <- str_sub(ncList[1], start = 15, end = 22)
# endDate <- str_sub(ncList[length(ncList)], start = 15, end = 22)
# 
# # apply the function
# system.time(llply(ncList, read_nc, region = "BC", csvDir = OISST.csv.dir, .parallel = TRUE))
# # system.time(llply(ncList, read_nc, region = "CC", csvDir = OISST.csv.dir, .parallel = TRUE))
# # system.time(llply(ncList, read_nc, region = "CalC", csvDir = OISST.csv.dir, .parallel = TRUE))
# # system.time(llply(ncList, read_nc, region = "HC", csvDir = OISST.csv.dir, .parallel = TRUE))
# 
# # Loading the data
# BC_avhrr_only_v2_Document_Document <- read_csv("~/Documents/OISST_subset/BC-avhrr-only-v2.Document-Document.csv" )
# names(BC_avhrr_only_v2_Document_Document)<-c("lon","lat", "temp", "date")
# 
# # Saving the data
# save(BC_avhrr_only_v2_Document_Document, file = "Data/OISST.RData")
```

# Extracting G1SST

```{r}
# bbox <- data.frame(BC = c(-35, -25, 15, 20)) # Benguela Current
# library(stringr)
# library(tidyverse)
# library(reshape2)
# library(ncdf4) # library for processing netCDFs
# library(plyr)
# library(lubridate)
# library(data.table)
# library(doMC); doMC::registerDoMC(cores = 7)
# ncDir <- "/home/amieroh/Documents/Data/Datasets/G1SST/daily"
# csvDir <- "/media/amieroh/Seagate Expansion Drive/Extracted G1SST"
# 
# # #          1         2         3         4
# # # 12345678901234567890123456789012345678901
# # # 20020601-JPL-L4UHfnd-GLOB-v01-fv04-MUR.nc
# #          1         2         3         4         5         6
# # 1234567890123456789012345678901234567890123456789012345678901
# # 20100609-JPL_OUROCEAN-L4UHfnd-GLOB-v01-fv01_0-G1SST_subset.nc
# 
# 
# # ncFile <- '/home/amieroh/Documents/Data/Datasets/MUR/daily/20020606-JPL-L4UHfnd-GLOB-v01-fv04-MUR.nc'
#   ncFun <- function(ncFile = ncFile, region = region, csvDir = csvDir) {
#     coords <- bbox[, region]
#     nc <- nc_open(ncFile)
#     pathLen <- nchar(paste0(ncDir, "/")) + 1
#     fNameStem <-
#       substr(basename(ncFile), 10, 58)
#     fDate <- substr(basename(ncFile), 1, 8)
#     LatIdx <- which(nc$dim$lat$vals > coords[1] & nc$dim$lat$vals < coords[2])
#     LonIdx <- which(nc$dim$lon$vals > coords[3] & nc$dim$lon$vals < coords[4])
#     sst <- ncvar_get(nc, varid = "analysed_sst") %>%
#       round(4)
#     dimnames(sst) <- list(lon = nc$dim$lon$vals,
#                           lat = nc$dim$lat$vals)
#     nc_close(nc)
#     sst <- as_tibble(melt(sst, value.name = "temp"))
#     sst$t <- ymd(fDate)
#     na.omit(sst)
#     fwrite(sst,
#            file = paste0(csvDir, "/", region, "-", fNameStem, "-", strtDate, "-", endDate, ".csv"),
#            append = TRUE, col.names = FALSE)
#     rm(sst)
#   }
# 
# 
#   ncList <- list.files(path = paste0(ncDir), pattern = "*.nc", full.names = TRUE, include.dirs = TRUE)
#   ncFirst <- head(list.files(path = paste0(ncDir, "/"), pattern = "*.nc", full.names = FALSE), 1)
#   ncLast <- tail(list.files(path = paste0(ncDir, "/"), pattern = "*.nc", full.names = FALSE), 1)
#   strtDate <- str_sub(ncFirst, start = 1, end = 8)
#   endDate <- str_sub(ncLast, start = 1, end = 8)
# 
# llply(ncList, ncFun, region = "BC", csvDir = csvDir, .parallel = TRUE)

```

# Using the upwelling metrics created in `upwell.IDX.Rmd` Identify when upwelling occurs at the particular site. 
# Is this upwelling event seen throughout the different distances from the coastline
# Using CMC, MUR, OISST and SACTN_US to determine wether the upwelling events detected are present in each of the datasets

## Function
Determining the temperatures at the various distances from the coastline

```{r}
# # These following three objects (MUR, OISST, CMC) need to be the complete set of lon/lat values for your satellite data
# MUR <- MUR %>%
#   select(lon, lat) %>%
#   mutate(product = "MUR")
# 
# # Decided to work with OISST and CMC as both has a time series of 30years
OISST_prod <- OISST %>%
  select(lon, lat) %>%
  unique() %>%
  mutate(product = "OISST")
# 
CMC_prod <- CMC %>%
  select(lon, lat) %>%
  unique() %>%
  mutate(product = "CMC")
# 
sat_data <- rbind(CMC_prod, OISST_prod) %>% 
#   #rbind(., CMC) %>% 
select(product, lon, lat)
# 
sat_pixels <- sat_data %>%
select(product, lon, lat) %>%
unique()
# 
# ## For testing the nest/map pipeline
# # df <- site_pixels %>%
# #   filter(site == "Lamberts Bay") %>%
# #   select(-site)
# 
match_func <- function(df){
  df <- df %>%
    dplyr::rename(lon_site = lon, lat_site = lat)
  OISST_index <- OISST_prod[as.vector(knnx.index(as.matrix(OISST_prod[,c("lon", "lat")]),
                                                 as.matrix(df[,c("lon_site", "lat_site")]), k = 1)),] %>%
    cbind(., df)
  CMC_index <- CMC_prod[as.vector(knnx.index(as.matrix(CMC_prod[,c("lon", "lat")]),
                                             as.matrix(df[,c("lon_site", "lat_site")]), k = 1)),] %>%
    cbind(., df)
  res <- rbind(OISST_index, CMC_index)
  return(res)
}

# # Find the nearest pixels to each spot along the transect
# # NB: SOme pixels are used more thanonce in a transect as the spacing isn't quite larger enough between transect
# # points to not fall inside of the same 25 KM pixel
pixel_match <- site_pixels %>%
  group_by(site) %>%
  group_modify(~match_func(.x))

# # You may then use the 'pixel_match' object to filter out the desired pixels from the full satellite products
OISST_fill <- right_join(OISST, filter(pixel_match, product == "OISST"), by = c("lon", "lat"))
CMC_fill <- right_join(CMC, filter(pixel_match, product == "CMC"), by = c("lon", "lat"))
# #SACTN_fill <- right_join(SACTN, filter(pixel_match, product == "SACTN"), by = c("lon", "lat"))
# 
# Clean up some RAM space
rm(OISST, CMC); gc()
# 
# # sites <- c("Port Nolloth", "Lamberts Bay", "Saldanha Bay", "Sea Point")
# # # In the SACTN dataset Hout Bay only has data until 2005. Hout Bay will now be removed from this study
# # # Hout Bay will be ignored
selected_sites <- c("Port Nolloth", "Lamberts Bay", "Sea Point", "Saldanha Bay")
# 
OISST_fill <- OISST_fill %>%
  filter(site %in% selected_sites)

CMC_fill <- CMC_fill %>%
  filter(site %in% selected_sites)
# 
# 
# # All the code below can be viewed in upwell_IDX.Rmd
# # Next to run upwelling index
# # UI Created using SAWS wind data (Find in upwell_IDX_Rmd)
# load("Data/UI_angle.RData")
# 
upwelling <- UI_angle %>%
  dplyr::rename(temp = ui.saws) %>%
  group_by(site) %>%
  # mutate(min_t = min(t),
  #        max_t = max(t)) %>%
  nest() %>% # apply the following functions to all of the variables in te dataset
  mutate(clim = purrr::map(data, ts2clm, climatologyPeriod = c("1997-01-01", "2015-12-31")), # creating a column of climatologies. Column will be named clim
         # NB: A threshold of 3 appeared to be far to strict
         # purr::map - apllies a function to each element of a vector
         exceed = purrr::map(clim, exceedance, minDuration = 1, threshold = 1)) %>%  #Upwelling cannot be descrbed as an event. Upwelling can last for a few hours. Given that we have daily data, upwelling events minimum duration here will be 1day
  # Detect consecutive days in exceedance of a given threshold.
  # mutate() %>%
  select(-data, -clim) %>%
  unnest() %>%
  filter(row_number() %% 2 == 1) %>%
  unnest() %>% # creates a column for each variables
  dplyr::rename(ui.saws = temp) %>% # rename upwelling index vale to temp so that it could work with the function
  select(site, t, ui.saws, exceedance)

# Now applying the Upwelling func
# NB: This only pulls out the event results and not the climatology results
# This is done to keep the output tidy because group_modify() may only create data.frame type outputs
# To create a list output one would use group_map(),
# but this then loses the labels of which sites etc. the results belong to
detect_event_custom <- function(df){
  res <- detect_event(df, threshClim2 = df$exceedance, minDuration = 1, coldSpells = T)$event # 1 or 3?
  return(res)
}
# 
ts2clm_custom <- function(df){
  # The climatology base period used here is up for debate...
  # The choice of the 25th percentile threshold also needs to be justified and sensitivty tested
  res <- ts2clm(df, pctile = 25, climatologyPeriod = c("1992-01-01", "2016-12-31"))
  return(res)
}
# 
# Calculate the upwelling event metrics
upwelling_detect_event <- function(df){
  upwell_base <- df %>%
    dplyr::rename(t = date) %>%
    group_by(site, product, heading, distance, lon, lat) %>%
    group_modify(~ts2clm_custom(.x)) %>%
    left_join(upwelling, by = c("site", "t")) %>%
    filter(!is.na(exceedance)) %>%
    group_by(site, product, heading, distance, lon, lat) %>%
    group_modify(~detect_event_custom(.x))
  }
# 
OISST_upwell_base <- upwelling_detect_event(df = OISST_fill)
save(OISST_upwell_base, file = "Data/OISST_upwell_base.RData")
CMC_upwell_base <- upwelling_detect_event(df = CMC_fill)
save(CMC_upwell_base, file = "Data/CMC_upwell_base.RData")
# 
# Here we remove the site Hout Bay so that we have a long time series. The length of Hout Bay time series ends in 200. Many sites change from here
SACTN_US <- SACTN_US %>%
  filter(site %in% selected_sites)

load("Data/site_list_v4.2.RData")

SACTN_upwell_base <- SACTN_US %>%
  left_join(site_list[,c(4, 5, 6)], by = "index")%>%
    dplyr::rename(t = date) %>%
    group_by(site, lon, lat) %>%
    group_modify(~ts2clm_custom(.x)) %>%
    left_join(upwelling, by = c("site", "t")) %>%
    filter(!is.na(exceedance)) %>%
    group_by(site, lon, lat) %>%
    group_modify(~detect_event_custom(.x))

save(SACTN_upwell_base, file = "Data/SACTN_upwell_base.RData")
```

Loading the data
    This is the data obtained once the upwelling signals were filtered out

```{r}
load("Data/OISST_upwell_base.RData")
load("Data/CMC_upwell_base.RData")
load("Data/SACTN_upwell_base.RData")
load("Data/MUR_upwell_base.RData")
load("Data/G1SST_upwell_base.RData")

# Removing the distance of 20 and 40kms
library(dplyr)
removing_distance_func <- function(df){
  removing_dist_func<- df %>% 
       filter(!distance %in% c(20000,40000))
}

OISST_final <- removing_distance_func(df = OISST_upwell_base)
G1SST_final <- removing_distance_func(df = G1SST_upwell_base)
MUR_final <- removing_distance_func(df = MUR_upwell_base)
CMC_final <- removing_distance_func(df = CMC_upwell_base)

# save(OISST_final, file = "Data/OISST_final.RData")
# save(G1SST_final, file = "Data/G1SST_final.RData")
# save(MUR_final, file = "Data/MUR_final.RData")
# save(CMC_final, file = "Data/CMC_final.RData")
```

To accurately compare 
  Start date CMC start date 1991-09-02 end date 2017-03-15
  Start date OISST start date 1981-09- 01  and end date 2018-09-28
  Start date SACTN start date 1973 and end date 2017-12-16
  
```{r}
#glm to determine if there is a difference in the number of events recorded at different at every distance

load("Data/Count/OISST_count.RData")
load("Data/Count/G1SST_count.RData")
load("Data/Count/MUR_count.RData")
load("Data/Count/CMC_count.RData")
G1SST_count <- G1SST_count %>% 
  mutate(src = "G1SST")

combined <- rbind(CMC_count,G1SST_count,MUR_count,OISST_count)

options(scipen = 999)

anova_func <- function(df){
  sites_aov <- aov(distance ~ no_observation * src, data = df)
return(sites_aov)
}

combined <- anova_func(df = combined)
summary(combined)

m_coeff <- function(df){
  res <- lm(formula = val ~ date_peak, data = df)
  res_coeff <- round(as.numeric(res$coefficient[2]), 4)
}
# Changes in upwelling metrics
lm_func <- function(df){
  upwell_lm <- df %>% 
  select(-c(index_start:index_end)) %>% 
  gather(key = "var", value = "val", -c(site:date_end)) %>% 
  group_by(site, var, distance) %>% 
  nest() %>% 
  mutate(slope = purrr::map(data, lm_coeff)) %>% 
  select(-data) %>% 
  unnest() %>% 
  # convert from daily to decadal values
  mutate(slope = slope * 365.25*10)
}

OISST_lm <- lm_func(df = OISST_upwell_base)
CMC_lm <- lm_func(df = CMC_upwell_base)

SACTN_lm <- SACTN_upwell_base %>% 
  select(-c(index_start:index_end)) %>% 
  gather(key = "var", value = "val", -c(site:date_end)) %>% 
  group_by(site, var) %>% 
  nest() %>% 
  mutate(slope = purrr::map(data, lm_coeff)) %>% 
  select(-data) %>% 
  unnest() %>% 
  # convert from daily to decadal values
  mutate(slope = slope * 365.25*10)
```
  

As a common date we will use a start date from 1992-01-31 and end date 16-12-31

```{r}
# Generalosed linear models

# Generalized Linear Models- Look at the difference in metrics of in situ upwelling and remotely sensed SST data upwelling 
# Generalized linear models are fit using the glm( ) function. The form of the glm function is glm(formula, family=familytype(link=linkfunction), data=)

# trends_duration_func <- function(df){
#   upwellmodel <- glm(SACTN_upwell_base$duration[SACTN_upwell_base$event_no] ~ seq(1:length(SACTN_upwell_base$duration[SACTN_upwell_base$event_no])), 
#                      family = poisson(link = "log"))
#   upwellmodel0 <- glm(SACTN_upwell_base$duration[SACTN_upwell_base$event_no] ~ 1, family = poisson(link = "log")) # intercept only
#   dat2 <- data.frame(site = SACTN_upwell_base$site, upwelltrend = round(as.numeric(coef(upwellmodel)[2]*10),1),
#                        upwellR2 = round(1-logLik(upwellmodel)/logLik(upwellmodel0),2), # McFadden's pseudo-R2
#                        upwell.val = round(coef(summary(upwellmodel))[,4][2],2))
# }
# 
# OISST_trends_duration_func <- trends_duration_func(df = OISST_upwell_base)
# CMC_trends_duration_func <- trends_duration_func(df = CMC_upwell_base)
# SACTN_trends_duration_func <- trends_duration_func(df = SACTN_upwell_base)
# 
# 
# ### Intensity: Chnaged the family and link because of the negative values within the dataset 
# trends_intensity_func <- function(df){
#   upwellmodel <- glm(SACTN_upwell_base$intensity_mean[SACTN_upwell_base$event_no] ~ seq(1:length(SACTN_upwell_base$intensity_mean[SACTN_upwell_base$event_no])), 
#                      family = gaussian(link = "identity"))
#   upwellmodel0 <- glm(SACTN_upwell_base$intensity_mean[SACTN_upwell_base$event_no] ~ 1, family = gaussian(link = "identity")) # intercept only
#   dat2 <- data.frame(site = SACTN_upwell_base$site, upwelltrend = round(as.numeric(coef(upwellmodel)[2]*10),1),
#                        upwellR2 = round(1-logLik(upwellmodel)/logLik(upwellmodel0),2), # McFadden's psesudo-R2
#                        upwell.val = round(coef(summary(upwellmodel))[,4][2],2))
# }
# 
# OISST_trends_intensity_func <- trends_intensity_func(df = OISST_upwell_base)
# CMC_trends_intensity_func <- trends_intensity_func(df = CMC_upwell_base)
# SACTN_trends_intensity_func <- trends_intensity_func(df = SACTN_upwell_base)
```

# From the years 1992 - 2017

```{r}
# Which pixels showed the highest upwelling counts within the different datasets
# Which site showed the most intense upwelling within the different datasets

metric_func <- function(df){
 metrics <-df %>% 
  filter(year(date_start) %in% 2011:2014) %>% 
  #mutate(year = year(date_start)) %>% 
  group_by(distance, site) %>% 
  summarise(mean_intensity = mean(intensity_mean),
            sum_events = sum(event_no)) %>% 
   select(site, distance, mean_intensity, sum_events)
}

OISST_metrics <- metric_func(OISST_upwell_base)
CMC_metrics <- metric_func(CMC_upwell_base)

# No of upwelling events found at the different sites
SACTN_metrics <- SACTN_upwell_base %>% 
  filter(year(date_start) %in% 2011:2014) %>% 
  group_by(site) %>% 
  summarise(mean_intensity = mean(intensity_mean),
            sum_events = sum(event_no)) %>% 
  select(site, mean_intensity, sum_events)

# Create a table showing these metrics


```

## Using series of general linear hypothese to look for differences in upwelling signal metrics between datasets and between sites (?)
# Is there a significant difference in the duration/intensity etc between the datasets at a particular site


```{r}

library(tidyverse)
library(multcomp)


load("Data/OISST_final.RData")
load("Data/G1SST_final.RData")
#load("Data/SACTN_upwell_base.RData")
load("Data/MUR_final.RData")
load("Data/CMC_final.RData")

combined_products <- rbind(OISST_final,CMC_final,MUR_final,G1SST_final)

metric_4years <- combined_products %>% 
   filter(year(date_start) %in% 2011:2014)


metrics <- metric_4years %>% 
  mutate(year = year(date_start)) %>% 
  group_by(product, site) %>% 
  summarise(y = n(),
            mean_intensity = mean(intensity_mean),
            mean_dur = mean(duration),
            mean_cumIn = mean(intensity_cumulative)) %>% 
  rename(count = y)


lmod <- lm(mean_intensity ~ mean_dur, data = metrics)
summary(lmod)

glht(lmod, linfct = K)

```
















